{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de09607-c834-4e52-bb1e-17877fe860e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.cuda.is_available()\n",
    "\n",
    "import time\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import os\n",
    "from scipy import io\n",
    "import pickle\n",
    "device='cuda'\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "#from matplotlib import cm\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import sys\n",
    "#inp = int(float(sys.argv[1])-1)\n",
    "inp=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5368103e-126b-4c1c-ac94-f564f0f2abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Manager(nn.Module):\n",
    "    \n",
    "    def __init__(self,tr_prc=0.8,Dataset=1, Black_and_White=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if Dataset==1:\n",
    "        \n",
    "            self.Y=torch.tensor(np.load('../../Robot Self Dataset New/data_hands_closer/states.npy').astype(\"float32\"),device='cpu').to(torch.float16)\n",
    "            self.A=torch.tensor(np.load('../../Robot Self Dataset New/data_hands_closer/actions.npy').astype(\"float32\"),device='cpu').to(torch.float16)\n",
    "            \n",
    "            N_files=10\n",
    "            self.X=[]\n",
    "            self.L=[]\n",
    "            \n",
    "            for n in range(0,N_files):\n",
    "    \n",
    "                title_file='../../Robot Self Dataset New/data_hands_closer/images-'+str(n)+'.npz'\n",
    "                \n",
    "                Image=np.load(title_file)\n",
    "                \n",
    "                ## mean Converts to black and white\n",
    "                #self.X.append( torch.mean(torch.tensor(Image['arr_0'][1,...]).to(torch.float16),3,keepdim=True) )\n",
    "                self.X.append( torch.tensor(Image['arr_0'][1,...]).to(torch.uint8) )\n",
    "\n",
    "                title_file='../../Robot Self Dataset New/data_hands_closer/labels-'+str(n)+'.npz'\n",
    "                Labels=np.load(title_file)\n",
    "\n",
    "                if n>=int(tr_prc*10):\n",
    "                    self.L.append( (torch.tensor(Labels['arr_0'])[1,:,:,:,1,:]).unsqueeze(-2).to(torch.uint8) )\n",
    "\n",
    "            self.X=torch.stack(self.X,0).reshape([-1, self.X[0].size()[1], self.X[0].size()[2], self.X[0].size()[3], self.X[0].size()[4] ])\n",
    "            self.X=self.X.permute(0,3,1,2,4)\n",
    "            \n",
    "            self.N_seq=self.X.size()[0]\n",
    "            self.N_tr=int(tr_prc*self.N_seq)\n",
    "            self.N_val=int( (self.N_seq-self.N_tr)/2 )\n",
    "            \n",
    "            #rand_perm=np.random.permutation(self.N_seq)\n",
    "                        \n",
    "            self.L=torch.stack(self.L,0).reshape([-1, self.L[0].size()[1], self.L[0].size()[2], self.L[0].size()[3], self.L[0].size()[4] ])\n",
    "            self.L=self.L.permute(0,3,1,2,4)\n",
    "\n",
    "            #self.L=self.L[rand_perm,...]\n",
    "            #self.L=self.L[self.N_tr:,...]\n",
    "\n",
    "            \n",
    "\n",
    "        if Dataset==2:\n",
    "\n",
    "            self.Y=torch.tensor(np.load('../../Data_Tiny_Catch/data_1000/states.npy')).to(torch.float16)\n",
    "            self.A=torch.tensor(np.load('../../Data_Tiny_Catch/data_1000/actions.npy')).to(torch.float16)\n",
    "            \n",
    "            N_files=10\n",
    "            Images=[]\n",
    "            self.X=[]\n",
    "            \n",
    "            for n in range(1,N_files+1):\n",
    "                \n",
    "                title_file='../../Data_Tiny_Catch/data_1000/images-'+str(n)+'.npz'\n",
    "                \n",
    "                Image=np.load(title_file)\n",
    "                self.X.append(torch.tensor(Image['arr_0']))\n",
    "            \n",
    "            self.X=torch.stack(self.X,0).reshape([-1, self.X[0].size()[1], self.X[0].size()[2], self.X[0].size()[3], self.X[0].size()[4] ])\n",
    "            self.X=self.X.permute(0,3,1,2,4)\n",
    "\n",
    "        self.X_M=torch.max(self.X)\n",
    "\n",
    "        self.N_ch=self.X.size()[1]\n",
    "        self.T_flow=10\n",
    "        self.alpha=1\n",
    "\n",
    "        self.ema_kernel=torch.zeros([1,self.T_flow,1,1],device=device)\n",
    "        self.ema_kernel[0,:,0,0]=(torch.pow((1-self.alpha),torch.arange(0,self.T_flow))*self.alpha)\n",
    "        \n",
    "        self.Compute_Flow()\n",
    "        \n",
    "        self.Hei=self.X.size()[1]\n",
    "        self.Len=self.X.size()[2]\n",
    "        self.T=self.X.size()[-1]\n",
    "        \n",
    "        #self.X=self.X[rand_perm,...]\n",
    "        #self.X_flow=self.X_flow[rand_perm,...]\n",
    "        #self.Y=self.Y[rand_perm,:,:]\n",
    "        #self.A=self.A[rand_perm,...]\n",
    "        \n",
    "        self.X_tr_flow=self.X_flow[0:self.N_tr,...]\n",
    "        self.X_tr=self.X[0:self.N_tr,...]\n",
    "        \n",
    "        self.X_te_flow=self.X_flow[self.N_tr:,...]\n",
    "        self.X_te=self.X[self.N_tr:,...]\n",
    "        \n",
    "        self.Y_tr=self.Y[0:self.N_tr,...]\n",
    "        self.Y_te=self.Y[self.N_tr:,...]\n",
    "\n",
    "        self.A_tr=self.A[0:self.N_tr,...]\n",
    "        self.A_te=self.A[self.N_tr:,...]\n",
    "\n",
    "        self.resolution=self.X_tr.size()[-2]\n",
    "\n",
    "    def Compute_Flow(self):\n",
    "\n",
    "        T=self.X.size()[-1]\n",
    "\n",
    "        self.X_flow=torch.zeros([self.X.size()[0],1,self.X.size()[2],self.X.size()[3],self.X.size()[4]],dtype=torch.uint8)\n",
    "        \n",
    "        for t in range(1,T):\n",
    "\n",
    "            x2=self.X[...,t].to(torch.uint8)/self.X_M\n",
    "            x1=self.X[...,t-1].to(torch.uint8)/self.X_M\n",
    "\n",
    "            delta=(torch.mean(x2-x1,1,keepdim=True))\n",
    "            \n",
    "            self.X_flow[...,t]=(1-self.alpha)*self.X_flow[...,t-1]+self.alpha*(delta+1)/2\n",
    "\n",
    "        #min_val, max_val=torch.aminmax(self.X_flow)\n",
    "        \n",
    "        #self.X_flow=(self.X_flow+1)/(2)\n",
    "        \n",
    "    def Normalise(self):\n",
    "\n",
    "        self.m=self.Y_tr.mean(0).unsqueeze(0)\n",
    "        self.std=torch.sqrt(self.Y_tr.var(0).unsqueeze(0))\n",
    "        \n",
    "        epsilon=10**(-5)\n",
    "        \n",
    "        self.Y_tr=(self.Y_tr-self.m)/(self.std+epsilon)        \n",
    "        self.Y_te=(self.Y_te-self.m)/(self.std+epsilon)\n",
    "\n",
    "        self.m_a=self.A_tr.mean(0).unsqueeze(0)\n",
    "        self.std_a=torch.sqrt(self.A_tr.var(0).unsqueeze(0))\n",
    "        \n",
    "        self.A_tr=(self.A_tr-self.m_a)/(self.std_a+epsilon)\n",
    "        self.A_te=(self.A_te-self.m_a)/(self.std_a+epsilon)\n",
    "\n",
    "\n",
    "    def Unnormalise(self, Y, Y_true):\n",
    "\n",
    "        Y=Y*(self.std+epsilon)+self.m\n",
    "        Y_true=Y_true*(self.std+epsilon)+self.m\n",
    "\n",
    "        return Y, Y_true\n",
    "    \n",
    "    def Batch(self, batch_size):\n",
    "\n",
    "        rand_ind=torch.randint(0,self.X_tr.size()[0], [batch_size])\n",
    "        rand_t=torch.randint(0,self.X_tr.size()[-1], [batch_size])\n",
    "        \n",
    "        x_batch=self.X_tr[rand_ind,:,:,:,rand_t].float().to(device)/self.X_M\n",
    "        x_batch_flow=self.X_tr_flow[rand_ind,:,:,:,rand_t].float().to(device)\n",
    "        \n",
    "        x_batch=torch.concat([x_batch,x_batch_flow],1)\n",
    "        y_batch=self.Y_tr[rand_ind,:,rand_t].float().to(device)\n",
    "        \n",
    "        return x_batch, y_batch\n",
    "\n",
    "    def Evaluate(self, batch_size_te):\n",
    "\n",
    "        rand_ind=torch.randint(0,self.X_te.size()[0], [batch_size_te])\n",
    "        rand_t=torch.randint(1,self.X_te.size()[-1], [batch_size_te])\n",
    "\n",
    "        x_batch=self.X_te[rand_ind,:,:,:,rand_t].float().to(device)/self.X_M\n",
    "        x_batch_flow=self.X_te_flow[rand_ind,:,:,:,rand_t].float().to(device)\n",
    "        l_batch=self.L[rand_ind,:,:,:,rand_t].to(device)\n",
    "        \n",
    "        x_batch=torch.concat([x_batch,x_batch_flow],1)\n",
    "        y_batch=self.Y_te[rand_ind,:,rand_t].float().to(device)\n",
    "\n",
    "        return x_batch, y_batch, l_batch\n",
    "\n",
    "\n",
    "    def Batch_ODE(self, batch_size, T_horizon):\n",
    "        \n",
    "        A=torch.zeros([batch_size,self.A.size()[1],T_horizon],device=device)\n",
    "        \n",
    "        y=torch.zeros([batch_size,self.Y_tr.size()[1],T_horizon],device=device)\n",
    "        x=torch.zeros([batch_size,T_horizon,self.X_tr.size()[1]+1,self.X_tr.size()[2],self.X_tr.size()[3]],device=device)\n",
    "        \n",
    "        x0s=torch.zeros([batch_size,self.Y_tr.size()[1]],device=device)\n",
    "        \n",
    "        rand_ind=torch.randint(0, self.Y_tr.size()[0], [batch_size])\n",
    "        t_rand=torch.randint(0, self.Y_tr.size()[2]-T_horizon, [batch_size])\n",
    "        \n",
    "        for n in range(batch_size):\n",
    "            \n",
    "            A[n,:,:]=self.A_tr[rand_ind[n],:,t_rand[n]:t_rand[n]+T_horizon].float().to(device)\n",
    "\n",
    "            x[n,:,0:self.N_ch,:,:]=self.X_tr[rand_ind[n],:,:,:,t_rand[n]:t_rand[n]+T_horizon].unsqueeze(0).transpose(-1,0).squeeze().float().to(device)/self.X_M\n",
    "            x[n,:,-1,:,:]=self.X_tr_flow[rand_ind[n],:,:,:,t_rand[n]:t_rand[n]+T_horizon].unsqueeze(0).transpose(-1,0).squeeze().float().to(device)\n",
    "\n",
    "            y[n,:,:]=self.Y_tr[rand_ind[n],:,t_rand[n]:t_rand[n]+T_horizon].float().to(device)\n",
    "            \n",
    "            x0s[n,:]=self.Y_tr[rand_ind[n],:,t_rand[n]].float().to(device)\n",
    "        \n",
    "        t0s=t_rand.to(device)\n",
    "        \n",
    "        return x, y, A, x0s, t0s\n",
    "\n",
    "    def Evaluate_ODE(self, batch_size, T_horizon_val):\n",
    "        \n",
    "        A=torch.zeros([batch_size,self.A_te.size()[1],T_horizon_val],device=device)\n",
    "        \n",
    "        y=torch.zeros([batch_size,self.Y_te.size()[1],T_horizon_val],device=device)\n",
    "        x=torch.zeros([batch_size,T_horizon_val,self.X_te.size()[1]+1,self.X_te.size()[2],self.X_te.size()[3]],device=device)\n",
    "        l=torch.zeros([batch_size,T_horizon_val,self.L.size()[1],self.L.size()[2],self.L.size()[3]],device=device,dtype=torch.uint8)\n",
    "\n",
    "        x0s=torch.zeros([batch_size,self.Y_te.size()[1]],device=device)\n",
    "        \n",
    "        rand_ind=torch.randint(0, self.Y_te.size()[0], [batch_size],device=device)\n",
    "        t_rand=torch.randint(1, self.Y_te.size()[2]-T_horizon_val, [batch_size],device=device)\n",
    "        \n",
    "        for n in range(batch_size):\n",
    "            \n",
    "            A[n,:,:]=self.A_te[rand_ind[n],:,t_rand[n]:t_rand[n]+T_horizon_val].float().to(device)\n",
    "\n",
    "            x[n,:,0:self.N_ch,:,:]=self.X_te[rand_ind[n],:,:,:,t_rand[n]:t_rand[n]+T_horizon_val].unsqueeze(0).transpose(-1,0).squeeze().float().to(device)/self.X_M\n",
    "            x[n,:,-1,:,:]=self.X_te_flow[rand_ind[n],:,:,:,t_rand[n]:t_rand[n]+T_horizon_val].unsqueeze(0).transpose(-1,0).squeeze().float().to(device)\n",
    "            l[n,:,0:self.N_ch,:,:]=self.L[rand_ind[n],:,:,:,t_rand[n]:t_rand[n]+T_horizon_val].unsqueeze(0).transpose(-1,0).squeeze(-1).to(device)\n",
    "            \n",
    "            y[n,:,:]=self.Y_te[rand_ind[n],:,t_rand[n]:t_rand[n]+T_horizon_val].float().to(device)\n",
    "            \n",
    "            x0s[n,:]=self.Y_te[rand_ind[n],:,t_rand[n]].float().to(device)\n",
    "        \n",
    "        t0s=t_rand.to(device)\n",
    "        \n",
    "        return x, y, A, x0s, t0s, l\n",
    "\n",
    "\n",
    "# In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee9c626-a9ce-44f8-9711-0c68e7aac057",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=Data_Manager()\n",
    "\n",
    "batch_size=30\n",
    "T_horizon=50\n",
    "\n",
    "x_batch, y_batch=Data.Batch(batch_size)\n",
    "x_b, y_b, A_b, x0s, t0s=Data.Batch_ODE(batch_size, T_horizon=T_horizon)\n",
    "x_te, y_te, A_te, x0s, t0s, l_te=Data.Evaluate_ODE(batch_size, T_horizon_val=T_horizon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abc78bd-6fb9-4f83-b543-ae9e1bfbede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1, dropout=0.):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(out_ch)\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "        self.conv2=nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "        self.downsample = None\n",
    "        if in_ch != out_ch:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d( in_ch, out_ch, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = self.downsample(x) if self.downsample else x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        out = self.relu(x+identity)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, Ch):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.Ch=Ch\n",
    "        self.First_Block=[]\n",
    "        \n",
    "        self.First_Block.append( nn.Conv2d(Ch[0], Ch[1], kernel_size=3, stride=1, padding=1, bias=False) )\n",
    "        self.First_Block.append( nn.BatchNorm2d(Ch[1]) )\n",
    "        self.First_Block.append( nn.ReLU() )\n",
    "        self.First_Block.append( nn.MaxPool2d(kernel_size=3, stride=2, padding=1) )\n",
    "\n",
    "        self.First_Block=torch.nn.Sequential(*self.First_Block).to(device)\n",
    "        \n",
    "        self.layer=[]\n",
    "        self.layer.append( ResBlock(Ch[1], Ch[2], stride=1) )\n",
    "        \n",
    "        for n in range(3,len(Ch)):\n",
    "\n",
    "            self.layer.append( ResBlock(Ch[n-1], Ch[n], stride=2) ) \n",
    "\n",
    "        self.layer=torch.nn.Sequential(*self.layer).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x=self.First_Block(x)\n",
    "        out=self.layer(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ResBlockTranspose(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1, dropout=0.):\n",
    "        super(ResBlockTranspose, self).__init__()\n",
    "        \n",
    "        self.up = (stride == 2)\n",
    "        \n",
    "        self.conv1 = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=3, stride=stride,\n",
    "                                        padding=1, output_padding=1 if self.up else 0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "        self.upsample = None\n",
    "        if in_ch != out_ch or self.up:\n",
    "            self.upsample = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_ch, out_ch, kernel_size=1, stride=stride,\n",
    "                                   output_padding=1 if self.up else 0, bias=False),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.upsample(x) if self.upsample else x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        out = self.relu(x + identity)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet_Transpose(nn.Module):\n",
    "    def __init__(self, Ch):\n",
    "        super(ResNet_Transpose, self).__init__()\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        # Reverse the channel sequence from encoder: [256, 128, 64, 3]\n",
    "        rev_channels = Ch[::-1]\n",
    "\n",
    "        self.layers.append(ResBlockTranspose(rev_channels[0], rev_channels[1], stride=2))\n",
    "        for i in range(1, len(rev_channels) - 2):\n",
    "            self.layers.append(ResBlockTranspose(rev_channels[i], rev_channels[i+1], stride=2))\n",
    "        \n",
    "        # Final upsample block (optional: back to original resolution)\n",
    "        self.layers.append(nn.ConvTranspose2d(rev_channels[-2], rev_channels[-1],\n",
    "                                              kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        self.net = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, resolution, cnn_dim, latent_dim, sensor_dim, CUT=False):\n",
    "        super().__init__()\n",
    "\n",
    "        Chs=[4,16,32,64]\n",
    "        cnn_dim=Chs[-1]\n",
    "\n",
    "        self.encoder_visual_self = ResNet(Chs).to(device)\n",
    "        self.encoder_visual_other = ResNet(Chs).to(device)\n",
    "        \n",
    "        self.latent_dim=latent_dim\n",
    "        self.resolution=resolution\n",
    "\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        \n",
    "        self.project_self = torch.nn.Sequential(nn.Linear(cnn_dim * (resolution // 4) ** 2, 2*latent_dim),\n",
    "                                                nn.ReLU(), \n",
    "                                                nn.Linear(2*latent_dim, latent_dim))\n",
    "        \n",
    "        self.project_other = torch.nn.Sequential(nn.Linear(cnn_dim * (resolution // 4) ** 2, 2*latent_dim),\n",
    "                                                nn.ReLU(), \n",
    "                                                nn.Linear(2*latent_dim, latent_dim))\n",
    "\n",
    "        self.pro2lat=nn.Linear(sensor_dim, latent_dim)\n",
    "                                        \n",
    "        self.CUT=CUT\n",
    "        \n",
    "        if self.CUT:\n",
    "            self.pro2visual=nn.Linear(sensor_dim, latent_dim)\n",
    "                                        \n",
    "            \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            self.pro2lat.weight.zero_()\n",
    "            \n",
    "            if self.CUT:\n",
    "                self.pro2visual.weight.zero_()\n",
    "        \n",
    "            for i in range(sensor_dim):\n",
    "            \n",
    "                self.pro2lat.weight[i,i]=1\n",
    "                \n",
    "                if self.CUT:\n",
    "                    self.pro2visual.weight[i,i]=1\n",
    "\n",
    "    \n",
    "    def forward(self, x, pro_b, path_visual_self, path_visual_other):\n",
    "\n",
    "        batch_size=x.size()[0]\n",
    "        x_visual = x.reshape([batch_size,x.size()[1],self.resolution,self.resolution])\n",
    "        x_visual_self = self.encoder_visual_self(x_visual)  # [B*T, C, H/8, W/8]\n",
    "        x_visual_other = self.encoder_visual_other(x_visual)\n",
    "        \n",
    "        x_visual_self = self.flatten(x_visual_self)  # [B*T, C * H/8 * W/8]\n",
    "        x_visual_other = self.flatten(x_visual_other)\n",
    "\n",
    "        z_self_pro = self.pro2lat(pro_b)\n",
    "\n",
    "        z_self_pro2visual=torch.zeros_like(z_self_pro,device=device)\n",
    "        if self.CUT:    \n",
    "            z_self_pro2visual = self.pro2visual(pro_b)\n",
    "        \n",
    "        z_self_visual=self.project_self(x_visual_self).reshape([batch_size,-1])\n",
    "        \n",
    "        z_other=self.project_other(x_visual_other).reshape([batch_size,-1])*path_visual_other\n",
    "\n",
    "        return z_self_pro, z_self_visual, z_other, z_self_pro2visual\n",
    "\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, resolution, cnn_dim, latent_dim, sensor_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        Chs=[4,16,32,64]\n",
    "        cnn_dim=Chs[-1]\n",
    "        \n",
    "        self.latent_dim=latent_dim\n",
    "        self.resolution=resolution\n",
    "\n",
    "        self.cnn_initial_size = (resolution // 4, resolution // 4)\n",
    "\n",
    "        # Latent to feature map\n",
    "        self.cnn_dim=cnn_dim\n",
    "\n",
    "        self.project_self = torch.nn.Sequential(nn.Linear(latent_dim, 2*latent_dim),\n",
    "                                                nn.ReLU(), \n",
    "                                                nn.Linear(2*latent_dim, cnn_dim * self.cnn_initial_size[0] * self.cnn_initial_size[1]))\n",
    "        \n",
    "        self.project_other = torch.nn.Sequential(nn.Linear(latent_dim, 2*latent_dim),\n",
    "                                                nn.ReLU(), \n",
    "                                                nn.Linear(2*latent_dim, cnn_dim * self.cnn_initial_size[0] * self.cnn_initial_size[1]))\n",
    "\n",
    "        self.lat2pro=torch.nn.Sequential(nn.Linear(latent_dim, latent_dim),\n",
    "                                                nn.ReLU(), \n",
    "                                                nn.Linear(latent_dim, latent_dim),\n",
    "                                                nn.ReLU(),\n",
    "                                                nn.Linear(latent_dim, sensor_dim)       \n",
    "                                        )                    \n",
    "        self.decoder_visual_self=ResNet_Transpose(Chs)\n",
    "        self.decoder_visual_other=ResNet_Transpose(Chs)\n",
    "\n",
    "        \n",
    "    def forward(self, z_self, z_other):\n",
    "        \n",
    "        B = z_self.size(0)\n",
    "\n",
    "        pro_rec=self.lat2pro(z_self)\n",
    "        \n",
    "        x_self = self.project_self(z_self)\n",
    "        x_other = self.project_other(z_other)\n",
    "        \n",
    "        new_shape = [B, self.cnn_dim]\n",
    "        new_shape.extend(self.cnn_initial_size)\n",
    "        \n",
    "        x_self = x_self.view(*new_shape)\n",
    "        x_other = x_other.view(*new_shape)\n",
    "        \n",
    "\n",
    "        x_self=self.decoder_visual_self(x_self.reshape([B,self.cnn_dim,*self.cnn_initial_size]))\n",
    "        x_other=self.decoder_visual_other(x_other.reshape([B,self.cnn_dim,*self.cnn_initial_size]))\n",
    "\n",
    "        \n",
    "        mask_self = torch.mean(x_self[:, 0:3:, :self.resolution, :self.resolution],1,keepdim=True) \n",
    "        mask_self = torch.sigmoid(mask_self)\n",
    "        \n",
    "        mask_other = x_other[:, -1:, :self.resolution, :self.resolution]\n",
    "        \n",
    "        mask_other = ((1 - mask_self).detach())\n",
    "        \n",
    "        x_self = x_self[:, 0:-1, :self.resolution, :self.resolution]  # Crop if needed\n",
    "        x_other = x_other[:, 0:-1, :self.resolution, :self.resolution]  # Crop if needed\n",
    "        \n",
    "        img_self = x_self * mask_self\n",
    "        img_other = x_other * mask_other\n",
    "\n",
    "        return img_self, img_other, mask_self, mask_other, pro_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d637cf-80a7-4b44-bfa8-b5bdd6598ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODE_IntMethods:\n",
    "    \n",
    "    def __init__(self,F,dt):\n",
    "        \n",
    "        self.dt=dt\n",
    "        self.F=F.to(device)\n",
    "        self.device=device\n",
    "    \n",
    "    \n",
    "    def RK2(self,X,I,t):\n",
    "        \n",
    "        k1=self.F(X,t,I)\n",
    "        k2=self.F(X+k1*self.dt,t+self.dt,I)\n",
    "        x_new=X+1/2*(k1+k2)*self.dt\n",
    "        \n",
    "        return x_new\n",
    "    \n",
    "\n",
    "    def RK4(self,X,I,t):\n",
    "        \n",
    "        k1=self.F(X,t,I)\n",
    "        k2=self.F(X+k1*self.dt/2,t+self.dt/2,I)\n",
    "        k3=self.F(X+k2*self.dt/2,t+self.dt/2,I)\n",
    "        k4=self.F(X+k3*self.dt,t+self.dt,I)\n",
    "        x_new=X+1/6*(k1+2*k2+2*k3+k4)*self.dt\n",
    "        \n",
    "        return x_new\n",
    "    \n",
    "    def Compute_Dynamics(self,Input,x0,t0):\n",
    "        \n",
    "        T=Input.size()[2]\n",
    "        batch_size=x0.size()[0]\n",
    "        N=x0.size()[1]\n",
    "        \n",
    "        X=torch.zeros([batch_size,N,T],device=device)\n",
    "        X[:,:,0]=x0\n",
    "        \n",
    "        t=t0\n",
    "        \n",
    "        for n in range(1,T):\n",
    "            \n",
    "            if Input!=[]:\n",
    "                I=Input[:,:,n]\n",
    "\n",
    "            X[:,:,n]=self.RK4(X[:,:,n-1],I,t)\n",
    "                    \n",
    "            \n",
    "        return X\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self,F_Ns):\n",
    "        super().__init__()\n",
    "                \n",
    "        module=[]\n",
    "        \n",
    "        for n in range(1,F_Ns.size()[0]):\n",
    "                        \n",
    "            module.append(nn.Linear(F_Ns[n-1],F_Ns[n]))\n",
    "        \n",
    "            if n<F_Ns.size()[0]-1:\n",
    "            \n",
    "                module.append(nn.ReLU())\n",
    "                \n",
    "        self.F=nn.Sequential(*module)\n",
    "        \n",
    "        self.F_Ns=F_Ns\n",
    "                    \n",
    "    def forward(self,X,t=[],S=[]):\n",
    "        \n",
    "        if S!=[]:\n",
    "            \n",
    "            Input=torch.concat([X,S],1)\n",
    "            \n",
    "        else:\n",
    "            Input=X\n",
    "            \n",
    "        y=self.F(Input)\n",
    "        \n",
    "        return y\n",
    "\n",
    "\n",
    "class Model_ODE(nn.Module):\n",
    "    \n",
    "    def __init__(self, F_Ns, dt):\n",
    "        super().__init__()    \n",
    "        \n",
    "        self.F_Ns=F_Ns\n",
    "        \n",
    "        self.dt=dt\n",
    "        self.f=MLP(F_Ns).to(device)\n",
    "        self.F=ODE_IntMethods(self.f,dt)\n",
    "                    \n",
    "            \n",
    "    def Reset(self,Input,t0s):\n",
    "        \n",
    "        self.X=Input\n",
    "        self.t=t0s\n",
    "        \n",
    "    def ODE_step(self,Input):\n",
    "        \n",
    "        self.X=self.F.RK2(self.X,Input,self.t)\n",
    "        self.t=self.t+self.dt\n",
    "    \n",
    "    def forward(self,Input,y_true,X0s,t0s):\n",
    "        \n",
    "        T=y_true.size()[2]\n",
    "        batch_size=y_true.size()[0]\n",
    "        \n",
    "        y=torch.zeros([batch_size,y_true.size()[1],T],device=device)\n",
    "        \n",
    "        err=0\n",
    "    \n",
    "        self.Reset(X0s,t0s)\n",
    "        \n",
    "        y[:,:,0]=X0s.clone()\n",
    "        \n",
    "        I=Input\n",
    "        \n",
    "        for t in range(1,T):\n",
    "            \n",
    "            \n",
    "            if Input!=[]:\n",
    "            \n",
    "                self.ODE_step(I[:,:,t-1])\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                self.ODE_step([])\n",
    "                \n",
    "            \n",
    "            y[:,:,t]=self.X.clone()\n",
    "                \n",
    "        err=torch.mean((y_true[:,:,1:]-y[:,:,1:])**2,[0,1])\n",
    "        \n",
    "        return err, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d7df4-2c1f-4fb4-b405-9a7176d665b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import rgb_to_grayscale\n",
    "\n",
    "def to_grayscale_batch(x):\n",
    "    \n",
    "    \"\"\"\n",
    "    x: [B, C, H, W], C in {1, 3}. dtype uint8 or float.\n",
    "    Returns: [B, 1, H, W] float32 in [0, 1].\n",
    "    \"\"\"\n",
    "    if x.dtype == torch.uint8:\n",
    "        x = x.float() / 255.0  # normalize; keeps device (CPU/GPU)\n",
    "    if x.ndim != 4 or x.size(1) not in (1, 3):\n",
    "        raise ValueError(f\"Expected [B, C, H, W] with C=1 or 3, got {tuple(x.shape)}\")\n",
    "\n",
    "    # If already single-channel, pass through; otherwise convert RGB->gray\n",
    "    y = x if x.size(1) == 1 else rgb_to_grayscale(x)  # -> [B, 1, H, W]\n",
    "    return y\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "        \n",
    "\n",
    "\n",
    "class Self_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, resolution, cnn_dim, latent_dim, sensor_dim, \\\n",
    "                 F_Ns, dt, RK=2):             ## PREDICTIVE HYPER\n",
    "        super().__init__()    \n",
    "\n",
    "        self.latent_dim=latent_dim\n",
    "        self.cnn_dim=cnn_dim\n",
    "        self.sensor_dim=sensor_dim\n",
    "        \n",
    "        ## CORRELATION\n",
    "        self.encoder=Encoder(resolution, cnn_dim, latent_dim, sensor_dim).to(device)\n",
    "        self.decoder=Decoder(resolution, cnn_dim, latent_dim, sensor_dim).to(device)\n",
    "        self.opt=optim.Adam( list(self.encoder.parameters())+list(self.decoder.parameters()), lr=0.001)\n",
    "        \n",
    "        \n",
    "        ## PREDICTIVE\n",
    "        self.Predictive=Model_ODE(F_Ns, dt)\n",
    "        self.opt_Predictive=optim.Adam(self.Predictive.F.F.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    def Override_Predictive(self, F_Ns, dt, lr):\n",
    "\n",
    "        self.Predictive=Model_ODE(F_Ns, dt)\n",
    "        self.opt_Predictive=optim.Adam(self.Predictive.F.F.parameters(), lr=lr)\n",
    "\n",
    "    def Accuracy(self, img, lab, self_acc=True):\n",
    "\n",
    "\n",
    "        mask=to_grayscale_batch(img)\n",
    "        \n",
    "        b=img_self.size()[0]\n",
    "        tot_ind=128*128\n",
    "\n",
    "        if self_acc:\n",
    "            \n",
    "            lab=(lab==1).reshape([b, -1])\n",
    "            ind_sum=torch.sum( lab.float(), 1)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            lab=(lab>1).reshape([b, -1])\n",
    "            ind_sum=torch.sum( lab.float(), 1)\n",
    "\n",
    "        m=mask.reshape([b,-1])\n",
    "        \n",
    "        ind_sort=torch.sort(m,1)[1]\n",
    "        ind_sort_lab=torch.sort(lab.float(),1)[1]\n",
    "        \n",
    "        max_k = int(ind_sum.max().item())\n",
    "        topk   = ind_sort[:, -max_k:]                                        # [B, max_k]\n",
    "        topk_lab = ind_sort_lab[:, -max_k:]\n",
    "        valid  = torch.arange(max_k, device=device).unsqueeze(0) < ind_sum.unsqueeze(1)  # [B, max_k]\n",
    "        \n",
    "        \n",
    "        mask_flat = torch.zeros(b, m.size()[1], dtype=torch.bool, device=device)   # or dtype=torch.float32\n",
    "        mask_flat_lab = torch.zeros(b, m.size()[1], dtype=torch.bool, device=device)\n",
    "        \n",
    "        rows = torch.arange(b, device=device).unsqueeze(1).expand(-1, max_k)\n",
    "        mask_flat[rows[valid], topk[valid]] = True  \n",
    "        mask_flat_lab[rows[valid], topk_lab[valid]] = True \n",
    "        \n",
    "        norm=(mask_flat_lab*lab).float().sum()/(torch.tensor([ind_sum.max()*b, mask_flat_lab.sum()]).min())\n",
    "        acc=(mask_flat*lab).float().sum()/(torch.tensor([ind_sum.max()*b, mask_flat.sum()]).min())/norm\n",
    "        \n",
    "        \n",
    "        return acc\n",
    "        \n",
    "    \n",
    "    def Correlation_forward(self,x_b, pro_b, x_b_pred, pro_b_pred, A_b_pred, x0s, t0s, n, TRAIN=True, PRO=0, eta_consistency=0.):\n",
    "\n",
    "        batch_size=x_b.size()[0]\n",
    "\n",
    "        if n<10000:\n",
    "            \n",
    "            path_visual_self=torch.rand([batch_size,1],device=device)\n",
    "            path_visual_other=torch.zeros([batch_size,1],device=device)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            path_visual_self=torch.rand([batch_size,1],device=device)\n",
    "            path_visual_other=torch.ones([batch_size,1],device=device)\n",
    "            \n",
    "        \n",
    "        z_self_pro, z_self_visual, z_other, z_self_pro2visual=self.encoder(x_b, pro_b, path_visual_self, path_visual_other)\n",
    "        z_self=(1-path_visual_self)*z_self_pro+path_visual_self*z_self_visual\n",
    "        img_self, img_other, mask_self, mask_other, pro_rec = self.decoder(z_self,z_other)\n",
    "        \n",
    "        if n<10000:\n",
    "            \n",
    "            img = (img_self + img_other.detach())\n",
    "            \n",
    "        else:\n",
    "\n",
    "            img = (img_self + img_other)\n",
    "\n",
    "        consistency_loss1=torch.zeros([1], device=device)\n",
    "        \n",
    "        if PRO==1:\n",
    "            Z_, X0s=self.Correlation(x_b_pred, pro_b_pred)\n",
    "            consistency_loss1 = torch.mean(torch.pow(Z_[:,0:self.latent_dim,1:]-Z_[:,0:self.latent_dim,0:-1],2))\n",
    "        \n",
    "        recon_loss1 = torch.mean(torch.abs(img-x_b[:,0:-1,:,:]))\n",
    "\n",
    "        if self.encoder.CUT:\n",
    "            joint_loss1 = torch.mean(torch.pow(z_self_pro2visual-z_self_visual,2))\n",
    "        else:\n",
    "            joint_loss1=torch.zeros([1],device=device)\n",
    "            \n",
    "        recon_pro_loss1 = torch.mean(torch.pow(pro_rec-pro_b,2))\n",
    "        \n",
    "        err = recon_loss1  + 0.5*joint_loss1 + recon_pro_loss1 + eta_consistency*consistency_loss1\n",
    "\n",
    "        \n",
    "        if TRAIN:\n",
    "            \n",
    "            err.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "            self.opt_Predictive.zero_grad()\n",
    "\n",
    "        return recon_loss1.detach(), joint_loss1.detach(), recon_pro_loss1.detach(), consistency_loss1.detach(),\\\n",
    "        z_self.detach(), z_other.detach(), img.detach(), img_self.detach(), img_other.detach(), mask_self.detach(), mask_other.detach()\n",
    "\n",
    "\n",
    "    def Correlation_Eval(self,x_b, pro_b, x_b_pred, pro_b_pred, A_b_pred, x0s, t0s, n, lab, TRAIN=True, PRO=0):\n",
    "\n",
    "        batch_size=x_b.size()[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            path_visual_self=torch.rand([batch_size,1],device=device)\n",
    "            \n",
    "            if n<10000:\n",
    "                path_visual_other=torch.zeros([batch_size,1],device=device)\n",
    "\n",
    "            else:\n",
    "                path_visual_other=torch.ones([batch_size,1],device=device)\n",
    "                \n",
    "            z_self_pro, z_self_visual, z_other, z_self_pro2visual=self.encoder(x_b, pro_b, path_visual_self, path_visual_other)\n",
    "            z_self_mixed=(1-path_visual_self)*z_self_pro+path_visual_self*z_self_visual\n",
    "\n",
    "            consistency_loss=torch.zeros([1], device=device)\n",
    "            if PRO==1:\n",
    "                Z_, X0s=self.Correlation(x_b_pred, pro_b_pred)\n",
    "                consistency_loss = torch.mean(torch.pow(Z_[:,0:self.latent_dim,1:]-Z_[:,0:self.latent_dim,0:-1],2))\n",
    "                \n",
    "        \n",
    "            img_self_mixed, img_other_mixed, mask_self_mixed, mask_other_mixed, pro_rec = self.decoder(z_self_mixed,z_other)\n",
    "            \n",
    "            img_mixed = (img_self_mixed + img_other_mixed)\n",
    "            \n",
    "            recon_loss_mixed = torch.mean(torch.abs(img_mixed-x_b[:,0:-1,:,:]))\n",
    "\n",
    "            acc_self_mixed=self.Accuracy(img_self_mixed,lab,self_acc=True)\n",
    "            acc_other_mixed=self.Accuracy(img_other_mixed,lab,self_acc=False)\n",
    "            \n",
    "            if self.encoder.CUT:\n",
    "                \n",
    "                joint_loss = torch.mean(torch.pow(z_self_pro2visual-z_self_visual,2))\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                joint_loss=torch.zeros([1],device=device)\n",
    "            \n",
    "            recon_pro_loss = torch.mean(torch.pow(pro_rec-pro_b,2))\n",
    "    \n",
    "            \n",
    "            img_self_visual, img_other_visual, mask_self_visual, mask_other_visual, _ = self.decoder(z_self_visual,z_other)\n",
    "            img_visual = (img_self_visual + img_other_visual)\n",
    "    \n",
    "            recon_loss_visual = torch.mean(torch.abs(img_visual-x_b[:,0:-1,:,:]))\n",
    "\n",
    "            acc_self_visual=self.Accuracy(img_self_visual,lab,self_acc=True)\n",
    "            acc_other_visual=self.Accuracy(img_other_visual,lab,self_acc=False)\n",
    "            \n",
    "            \n",
    "            img_self_pro, img_other_pro, mask_self_pro, mask_other_pro, _ = self.decoder(z_self_pro,z_other)\n",
    "            img_pro = (img_self_pro + img_other_pro)\n",
    "\n",
    "            acc_self_pro=self.Accuracy(img_self_pro,lab,self_acc=True)\n",
    "            acc_other_pro=self.Accuracy(img_other_pro,lab,self_acc=False)\n",
    "            \n",
    "            recon_loss_pro = torch.mean(torch.abs(img_pro-x_b[:,0:-1,:,:]))\n",
    "    \n",
    "            cosine_pro=F.cosine_similarity(z_self_pro, z_self_mixed, dim=1).mean(0)\n",
    "            cosine_visual=F.cosine_similarity(z_self_visual, z_self_mixed, dim=1).mean(0)\n",
    "            cosine_vp=F.cosine_similarity(z_self_pro, z_self_visual, dim=1).mean(0)\n",
    "\n",
    "        \n",
    "        return recon_loss_mixed.detach(),  recon_loss_visual.detach(),  \\\n",
    "        recon_loss_pro.detach(), joint_loss.detach(), recon_pro_loss.detach(), consistency_loss.detach(), \\\n",
    "        acc_self_mixed.detach(), acc_other_mixed.detach(), acc_self_pro.detach(), acc_other_pro.detach(), acc_self_visual.detach(), acc_other_visual.detach(), \\\n",
    "        img_mixed.detach(), img_self_mixed.detach(), img_other_mixed.detach(), mask_self_mixed.detach(), mask_other_mixed.detach(), \\\n",
    "        img_visual.detach(), img_self_visual.detach(), img_other_visual.detach(), mask_self_visual.detach(), mask_other_visual.detach(), \\\n",
    "        img_pro.detach(), img_self_pro.detach(), img_other_pro.detach(), mask_self_pro.detach(), mask_other_pro.detach(), \\\n",
    "        cosine_pro.detach(), cosine_visual.detach(), cosine_vp.detach()\n",
    "            \n",
    "    \n",
    "    def Correlation(self, x_b, pro_b):\n",
    "        \n",
    "        T_hor=x_b.size()[1]\n",
    "        batch_size=x_b.size()[0]\n",
    "        x_b=x_b.view([batch_size*T_hor,x_b.size()[2],x_b.size(3),x_b.size(4)])\n",
    "        pro_b=pro_b.transpose(-1,-2).reshape([batch_size*T_hor,-1])\n",
    "\n",
    "        path_visual_self=torch.tile(torch.rand([batch_size,1,1],device=device),[1,T_hor,1]).reshape([batch_size*T_hor,-1])\n",
    "        path_visual_other=torch.ones([batch_size*T_hor,1],device=device)\n",
    "           \n",
    "        z_self_pro, z_self_visual, z_other, z_self_pro2visual=self.encoder(x_b, pro_b, path_visual_self, path_visual_other)\n",
    "            \n",
    "        z_=(1-path_visual_self)*z_self_pro+path_visual_self*z_self_visual\n",
    "        \n",
    "        z_b=z_.view([batch_size, T_hor, z_.size()[1]]).transpose(-1,-2)\n",
    "        X0s=z_b[...,0]\n",
    "        \n",
    "        return z_b, X0s\n",
    "\n",
    "    def Predictive_forward(self,x_b,y_b,A_b,t0s,TRAIN=True):\n",
    "\n",
    "        T_decode=5\n",
    "        T=x_b.size()[1]\n",
    "\n",
    "        Ts=int(np.floor(T/T_decode))*torch.arange(0,5)\n",
    "        Ts[-1]=T-1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            Z_, X0s=self.Correlation(x_b, y_b)\n",
    "\n",
    "        err_latent,Z_recon=self.Predictive.forward(A_b,Z_,X0s,t0s)\n",
    "        img_self=torch.zeros([1],device=device)\n",
    "        \n",
    "        if TRAIN==False:\n",
    "            \n",
    "            Z_decode=Z_recon[:,:,Ts]\n",
    "            batch_size=Z_decode.size()[0]\n",
    "            Z_decode=Z_decode.transpose(-1,-2).reshape([batch_size*T_decode, -1])\n",
    "\n",
    "            B=batch_size*T_decode\n",
    "            x_self = self.decoder.project_self(Z_decode)\n",
    "            \n",
    "            new_shape = [B, self.decoder.cnn_dim]\n",
    "            new_shape.extend(self.decoder.cnn_initial_size)\n",
    "            \n",
    "            x_self = x_self.view(*new_shape)\n",
    "            x_self=self.decoder.decoder_visual_self(x_self.reshape(*new_shape))\n",
    "            \n",
    "            mask_self = torch.mean(x_self[:, 0:3:, :self.decoder.resolution, :self.decoder.resolution],1,keepdim=True) \n",
    "            mask_self = torch.sigmoid(mask_self)\n",
    "            \n",
    "            x_self = x_self[:, 0:-1, :self.decoder.resolution, :self.decoder.resolution]  # Crop if needed\n",
    "            \n",
    "            img_self = x_self * mask_self\n",
    "            img_self = img_self.reshape([batch_size,T_decode,img_self.size()[1],img_self.size()[2],img_self.size()[3]])\n",
    "\n",
    "        Y_recon=self.decoder.lat2pro(Z_recon[:,0:self.latent_dim,:].transpose(-2,-1)).transpose(-2,-1)\n",
    "        \n",
    "        err_original=torch.pow(Y_recon-y_b,2).mean([0,1])\n",
    "        err=err_latent.mean()+err_original.mean()\n",
    "\n",
    "\n",
    "        if TRAIN:\n",
    "            \n",
    "            err.backward()\n",
    "            self.opt_Predictive.step()\n",
    "            self.opt.zero_grad()\n",
    "            self.opt_Predictive.zero_grad()\n",
    "\n",
    "        return err_original.detach(), err_latent.detach(), Z_recon.detach(), Y_recon.detach(), Z_.detach(), img_self.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2816340d-d217-491b-a8ac-0c5d1fed82d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution=128\n",
    "cnn_dim=32 \n",
    "\n",
    "latent_dim=100 \n",
    "sensor_dim=76\n",
    "\n",
    "\n",
    "eta=0.001\n",
    "\n",
    "X_DIM=latent_dim+latent_dim\n",
    "S_DIM=Data.A.size()[1]\n",
    "F_Ns=torch.tensor([latent_dim+A_b.size()[1],200,200,latent_dim])\n",
    "dt=0.1\n",
    "dt=torch.tensor(dt).float()\n",
    "\n",
    "self_model=Self_Model(resolution, cnn_dim, latent_dim, sensor_dim, \\\n",
    "                 F_Ns, dt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fcde44-4dc7-4962-bb12-03a80d392c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTINGS=[True, False]\n",
    "eta_consistency=0.\n",
    "\n",
    "inp=0\n",
    "scaff_self=SETTINGS[inp]\n",
    "\n",
    "import warnings, math\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "SAVE=True\n",
    "PLOT=False\n",
    "PRO=1\n",
    "\n",
    "LOAD=False\n",
    "\n",
    "if LOAD:\n",
    "\n",
    "    self_model=torch.load('Model_simple_after_pred_cutFalse.pt')\n",
    "    self_model.Override_Predictive(F_Ns, dt, lr=0.001)\n",
    "    \n",
    "\n",
    "N_train1=10000\n",
    "N_train2=50000\n",
    "N_train=N_train1+N_train2\n",
    "N_log=100\n",
    "\n",
    "N_checks1=np.unique(np.int32(np.exp(np.linspace(0,np.log(N_train1),N_log))))\n",
    "N_checks2=np.unique(np.int32(np.exp(np.linspace(0,np.log(N_train2),N_log))))+N_train1\n",
    "N_checks=np.concatenate([N_checks1, N_checks2],0)\n",
    "\n",
    "#N_checks=np.arange(0,101)*600\n",
    "\n",
    "N_check=N_checks.shape[0]\n",
    "\n",
    "ind_help=0\n",
    "\n",
    "MSE_Train_corr=torch.zeros([4,N_train])\n",
    "MSE_Tr_corr=torch.zeros([4,N_check])\n",
    "MSE_Te_corr=torch.zeros([6,N_check])\n",
    "ACC_Te=torch.zeros([6,N_check])\n",
    "\n",
    "Cosines=torch.zeros([3,N_check])\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "ind_help=0\n",
    "\n",
    "T_hor_penalty=3\n",
    "T_hor_val_penalty=5\n",
    "\n",
    "\n",
    "\n",
    "#############\n",
    "T_hor=50\n",
    "MSE_Train_pred=torch.zeros([2,N_train])\n",
    "MSE_Tr_pred=torch.zeros([2,N_check])\n",
    "T_hor_val=100\n",
    "MSE_Te_pred=torch.zeros([2,T_hor_val,N_check])\n",
    "\n",
    "\n",
    "for k in range(0,N_train1+N_train2):\n",
    "    \n",
    "    x_b, y_b=Data.Batch(batch_size)\n",
    "    X_b, Y_b, A_b, x0s, t0s=Data.Batch_ODE(batch_size, T_horizon=T_hor_penalty)\n",
    "    \n",
    "    recon_loss1, joint_loss1, consistency_loss1, pro_rec1, z_self, z_other, \\\n",
    "        img, img_self, img_other, mask_self, mask_other=self_model.Correlation_forward(x_b, y_b, X_b, Y_b, A_b, x0s, t0s, n=k, PRO=PRO, eta_consistency=eta_consistency)\n",
    "    \n",
    "    MSE_Train_corr[0,k]=recon_loss1.detach()\n",
    "    MSE_Train_corr[1,k]=pro_rec1.detach()\n",
    "    MSE_Train_corr[2,k]=joint_loss1.detach()\n",
    "    MSE_Train_corr[3,k]=consistency_loss1.detach()\n",
    "\n",
    "    err_latent=torch.zeros([1])\n",
    "    err_original=torch.zeros([1])\n",
    "    if not(scaff_self):\n",
    "\n",
    "        X_b, Y_b, A_b, x0s, t0s=Data.Batch_ODE(batch_size, T_horizon=T_hor)\n",
    "            \n",
    "        err_original, err_latent, Z_recon, Y_recon, _, _=self_model.Predictive_forward(X_b,Y_b,A_b,t0s,TRAIN=True)\n",
    "\n",
    "    if scaff_self and k>10000:\n",
    "\n",
    "        X_b, Y_b, A_b, x0s, t0s=Data.Batch_ODE(batch_size, T_horizon=T_hor)\n",
    "            \n",
    "        err_original, err_latent, Z_recon, Y_recon, _, _=self_model.Predictive_forward(X_b,Y_b,A_b,t0s,TRAIN=True)\n",
    "\n",
    "    \n",
    "    MSE_Train_pred[0,k]=err_latent.mean().detach()\n",
    "    MSE_Train_pred[1,k]=err_original.mean().detach()\n",
    "    \n",
    "    \n",
    "\n",
    "    if np.any(k==N_checks):\n",
    "        \n",
    "        if k>0:\n",
    "\n",
    "            mse_mean=torch.mean(MSE_Train_pred[:,k-N_checks[ind_help-1]:k],1)\n",
    "            MSE_Tr_pred[:,ind_help]=mse_mean\n",
    "            \n",
    "            mse_mean=torch.mean(MSE_Train_corr[:,k-N_checks[ind_help-1]:k],1)\n",
    "            MSE_Tr_corr[:,ind_help]=mse_mean\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            MSE_Tr_corr[:,ind_help]=MSE_Train_corr[:,k]\n",
    "            MSE_Tr_pred[:,ind_help]=MSE_Train_pred[:,k]\n",
    "        \n",
    "        x_b, y_b, lab=Data.Evaluate(batch_size*10)\n",
    "        X_te, Y_te, A_te, x0s, t0s, lab_=Data.Evaluate_ODE(batch_size, T_horizon_val=T_hor_val_penalty)\n",
    "\n",
    "        recon_loss_mixed, recon_loss_visual, recon_loss_pro, joint_loss, recon_pro_loss, consistency_loss, \\\n",
    "        acc_self_mixed, acc_other_mixed, acc_self_pro, acc_other_pro, acc_self_visual, acc_other_visual, \\\n",
    "        img_mixed, img_self_mixed, img_other_mixed, mask_self_mixed, mask_other_mixed, \\\n",
    "        img_visual, img_self_visual, img_other_visual, mask_self_visual, mask_other_visual, \\\n",
    "        img_pro, img_self_pro, img_other_pro, mask_self_pro, mask_other_pro, \\\n",
    "        cosine_mixed, cosine_visual, cosine_pro = self_model.Correlation_Eval(x_b, y_b, X_te, Y_te, A_te, x0s, t0s, k, lab, TRAIN=False, PRO=PRO)\n",
    "        \n",
    "        MSE_Te_corr[0,ind_help]=recon_loss_mixed.detach()\n",
    "        MSE_Te_corr[1,ind_help]=recon_loss_visual.detach()\n",
    "        MSE_Te_corr[2,ind_help]=recon_loss_pro.detach()\n",
    "        MSE_Te_corr[3,ind_help]=joint_loss.detach()\n",
    "        MSE_Te_corr[4,ind_help]=recon_pro_loss.detach()\n",
    "        MSE_Te_corr[5,ind_help]=consistency_loss.detach()\n",
    "\n",
    "        ACC_Te[0,ind_help]=acc_self_mixed\n",
    "        ACC_Te[1,ind_help]=acc_other_mixed\n",
    "        ACC_Te[2,ind_help]=acc_self_visual\n",
    "        ACC_Te[3,ind_help]=acc_other_visual\n",
    "        ACC_Te[4,ind_help]=acc_self_pro\n",
    "        ACC_Te[5,ind_help]=acc_other_pro\n",
    "        \n",
    "        Cosines[0,ind_help]=cosine_mixed\n",
    "        Cosines[1,ind_help]=cosine_visual\n",
    "        Cosines[2,ind_help]=cosine_pro\n",
    "\n",
    "    \n",
    "        print(k, 'CORRELATION ')\n",
    "        print(k,'Err Tr: ', MSE_Tr_corr[:,ind_help])\n",
    "        print(k,'Err Te: ', MSE_Te_corr[:,ind_help])\n",
    "        print(k,'Cosines: ', Cosines[:,ind_help])\n",
    "        print(k,'ACC: ', ACC_Te[:,ind_help])\n",
    "\n",
    "\n",
    "\n",
    "        ### PREDICTIVE\n",
    "        X_te, Y_te, A_te, x0s, t0s, lab_=Data.Evaluate_ODE(batch_size, T_horizon_val=T_hor_val)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            err_original, err_latent, Z_recon, Y_recon, Z_te, img_self=self_model.Predictive_forward(X_te,Y_te,A_te,t0s,TRAIN=False)\n",
    "\n",
    "        MSE_Te_pred[0,1:,ind_help]=err_latent.detach()\n",
    "        MSE_Te_pred[1,:,ind_help]=err_original.detach()\n",
    "        \n",
    "\n",
    "        print(k, 'PREDICTIVE')\n",
    "        print('Err Tr: ', MSE_Tr_pred[:,ind_help] )\n",
    "        print('Err Te: ', MSE_Te_pred[0,:,ind_help].mean(), MSE_Te_pred[1,:,ind_help].mean() ) \n",
    "        \n",
    "        \n",
    "        \n",
    "        ind_help+=1\n",
    "\n",
    "        if SAVE:\n",
    "\n",
    "            title_model='Model_simple_after_Simu_cutFalse_hpc_'+str(eta_consistency)+'_Scaff_self_'+str(scaff_self)+'.pt'\n",
    "            torch.save(self_model, title_model)\n",
    "\n",
    "            title_results='Results_simple_after_Simu_cutFalse_hpc_'+str(eta_consistency)+'_Scaff_self_'+str(scaff_self)\n",
    "            np.savez(title_results, MSE_Train_corr=MSE_Train_corr, MSE_Tr_corr=MSE_Tr_corr, MSE_Te_corr=MSE_Te_corr, ACC_Te=ACC_Te, Cosines=Cosines, \\\n",
    "                    MSE_Train_pred=MSE_Train_pred, MSE_Tr_pred=MSE_Tr_pred, MSE_Te_pred=MSE_Te_pred, N_checks=N_checks)\n",
    "            \n",
    "        \n",
    "        if PLOT:\n",
    "\n",
    "            for p in range(2):\n",
    "            \n",
    "                fig, ax = plt.subplots(3, 6, figsize=(10, 5))\n",
    "    \n",
    "                ax[0,0].imshow(x_b[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[0,1].imshow(img_mixed[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[0,2].imshow(img_self_mixed[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[0,3].imshow(img_other_mixed[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[0,4].imshow(mask_self_mixed[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[0,5].imshow(mask_other_mixed[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "\n",
    "    \n",
    "                ax[1,0].imshow(x_b[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[1,1].imshow(img_visual[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[1,2].imshow(img_self_visual[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[1,3].imshow(img_other_visual[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[1,4].imshow(mask_self_visual[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[1,5].imshow(mask_other_visual[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "\n",
    "\n",
    "                ax[2,0].imshow(x_b[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[2,1].imshow(img_pro[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[2,2].imshow(img_self_pro[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[2,3].imshow(img_other_pro[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[2,4].imshow(mask_self_pro[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[2,5].imshow(mask_other_pro[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "    \n",
    "                plt.show()\n",
    "\n",
    "\n",
    "            X_te, Y_te, A_te, x0s, t0s, lab_=Data.Evaluate_ODE(batch_size, T_horizon_val=T_hor_val)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "               _, _, _, _, Z_te, _=self_model.Predictive_forward(X_te,Y_te,A_te,t0s,TRAIN=False)\n",
    "\n",
    "\n",
    "            Z_te=Z_te.detach().to('cpu')\n",
    "            Z_recon=Z_recon.detach().to('cpu')\n",
    "    \n",
    "            Y_te=Y_te.detach().to('cpu')\n",
    "            Y_recon=Y_recon.detach().to('cpu')\n",
    "                \n",
    "            N_cases=3\n",
    "            fig, axs = plt.subplots(N_cases,2,figsize=(20,15))\n",
    "            \n",
    "            print('PLOTTING EXAMPLES OF MODEL PREDICTION VS DATA AT TRAINING ITERATION ', k)\n",
    "            \n",
    "            T_plot=200\n",
    "            for ind_ex in range(N_cases):\n",
    "    \n",
    "    \n",
    "                ind_ex_=np.random.randint(0,Z_te.size()[0])\n",
    "                axs[ind_ex,0].plot(Z_te[ind_ex_,0,0:T_plot].detach().to('cpu'),'o',color='red')\n",
    "                axs[ind_ex,0].plot(Z_recon[ind_ex_,0,0:T_plot].detach().to('cpu'),color='red', linewidth=2)\n",
    "                axs[ind_ex,0].plot(Z_te[ind_ex_,1,0:T_plot].detach().to('cpu'),'o',color='purple')\n",
    "                axs[ind_ex,0].plot(Z_recon[ind_ex_,1,0:T_plot].detach().to('cpu'),'--',color='purple', linewidth=2)\n",
    "                axs[ind_ex,0].plot(Z_te[ind_ex_,2,0:T_plot].detach().to('cpu'),'o',color='black')\n",
    "                axs[ind_ex,0].plot(Z_recon[ind_ex_,2,0:T_plot].detach().to('cpu'),'--',color='black', linewidth=2)\n",
    "    \n",
    "            \n",
    "                axs[ind_ex,1].plot(Y_te[ind_ex_,0,0:T_plot].detach().to('cpu'),'o',color='red')\n",
    "                axs[ind_ex,1].plot(Y_recon[ind_ex_,0,0:T_plot].detach().to('cpu'),color='red', linewidth=2)\n",
    "                axs[ind_ex,1].plot(Y_te[ind_ex_,1,0:T_plot].detach().to('cpu'),'o',color='purple')\n",
    "                axs[ind_ex,1].plot(Y_recon[ind_ex_,1,0:T_plot].detach().to('cpu'),'--',color='purple', linewidth=2)\n",
    "                axs[ind_ex,1].plot(Y_te[ind_ex_,2,0:T_plot].detach().to('cpu'),'o',color='black')\n",
    "                axs[ind_ex,1].plot(Y_recon[ind_ex_,2,0:T_plot].detach().to('cpu'),'--',color='black', linewidth=2)\n",
    "    \n",
    "    \n",
    "    \n",
    "                axs[ind_ex,0].set_xlabel('Time (a.u.)', fontsize=20)\n",
    "                axs[ind_ex,0].set_ylabel('Values', fontsize=20)\n",
    "    \n",
    "                axs[ind_ex,0].spines['right'].set_visible(False)\n",
    "                axs[ind_ex,0].spines['top'].set_visible(False)\n",
    "    \n",
    "                axs[ind_ex,1].set_xlabel('Time (a.u.)', fontsize=20)\n",
    "                axs[ind_ex,1].set_ylabel('Values', fontsize=20)\n",
    "    \n",
    "                axs[ind_ex,1].spines['right'].set_visible(False)\n",
    "                axs[ind_ex,1].spines['top'].set_visible(False)\n",
    "    \n",
    "    \n",
    "            plt.show()\n",
    "\n",
    "            fig, axs = plt.subplots(1,img_self.size()[1],figsize=(20,15))\n",
    "\n",
    "            for n in range(img_self.size()[1]):\n",
    "\n",
    "                axs[n].imshow(img_self[0,n,...].permute(1,2,0).detach().to('cpu'))\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "\n",
    "            del X_te, Y_te, A_te, x0s, t0s\n",
    "\n",
    "            del err_original, err_latent, Z_recon, Y_recon, Z_te, img_self\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2972b6-760c-4312-a8a6-86877c9cb8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
