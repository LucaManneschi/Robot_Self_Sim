{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d49a92f8-78e8-40f4-a6fd-c7e65559df54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/anaconda3/lib/python3.11/site-packages/torch/__init__.py:955: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789121465/work/torch/csrc/tensor/python_tensor.cpp:432.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.cuda.is_available()\n",
    "\n",
    "import time\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import os\n",
    "from scipy import io\n",
    "import pickle\n",
    "device='cuda'\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "#from matplotlib import cm\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import sys\n",
    "#inp = int(float(sys.argv[1])-1)\n",
    "inp=0\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4f68ec-32ff-454c-bea4-37916f6ba267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Manager(nn.Module):\n",
    "    \n",
    "    def __init__(self,tr_prc=0.8,Dataset=1, Black_and_White=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if Dataset==1:\n",
    "        \n",
    "            self.Y=torch.tensor(np.load('../../Robot Self Dataset New/data_hands_closer/states.npy').astype(\"float32\"),device='cpu').to(torch.float16)\n",
    "            self.A=torch.tensor(np.load('../../Robot Self Dataset New/data_hands_closer/actions.npy').astype(\"float32\"),device='cpu').to(torch.float16)\n",
    "            \n",
    "            N_files=10\n",
    "            self.X=[]\n",
    "            self.L=[]\n",
    "            \n",
    "            for n in range(0,N_files):\n",
    "    \n",
    "                title_file='../../Robot Self Dataset New/data_hands_closer/images-'+str(n)+'.npz'\n",
    "                \n",
    "                Image=np.load(title_file)\n",
    "                \n",
    "                ## mean Converts to black and white\n",
    "                #self.X.append( torch.mean(torch.tensor(Image['arr_0'][1,...]).to(torch.float16),3,keepdim=True) )\n",
    "                self.X.append( torch.tensor(Image['arr_0'][1,...]).to(torch.uint8) )\n",
    "\n",
    "                title_file='../../Robot Self Dataset New/data_hands_closer/labels-'+str(n)+'.npz'\n",
    "                Labels=np.load(title_file)\n",
    "\n",
    "                if n>=int(tr_prc*10):\n",
    "                    self.L.append( (torch.tensor(Labels['arr_0'])[1,:,:,:,1,:]).unsqueeze(-2).to(torch.uint8) )\n",
    "\n",
    "            self.X=torch.stack(self.X,0).reshape([-1, self.X[0].size()[1], self.X[0].size()[2], self.X[0].size()[3], self.X[0].size()[4] ])\n",
    "            self.X=self.X.permute(0,3,1,2,4)\n",
    "            \n",
    "            self.N_seq=self.X.size()[0]\n",
    "            self.N_tr=int(tr_prc*self.N_seq)\n",
    "            self.N_val=int( (self.N_seq-self.N_tr)/2 )\n",
    "            \n",
    "                        \n",
    "            self.L=torch.stack(self.L,0).reshape([-1, self.L[0].size()[1], self.L[0].size()[2], self.L[0].size()[3], self.L[0].size()[4] ])\n",
    "            self.L=self.L.permute(0,3,1,2,4)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "        if Dataset==2:\n",
    "\n",
    "            self.Y=torch.tensor(np.load('../Data_Tiny_Catch/data_1000/states.npy')).to(torch.float16)\n",
    "            self.A=torch.tensor(np.load('../Data_Tiny_Catch/data_1000/actions.npy')).to(torch.float16)\n",
    "            \n",
    "            N_files=10\n",
    "            Images=[]\n",
    "            self.X=[]\n",
    "            \n",
    "            for n in range(1,N_files+1):\n",
    "                \n",
    "                title_file='../Data_Tiny_Catch/data_1000/images-'+str(n)+'.npz'\n",
    "                \n",
    "                Image=np.load(title_file)\n",
    "                self.X.append(torch.tensor(Image['arr_0']))\n",
    "            \n",
    "            self.X=torch.stack(self.X,0).reshape([-1, self.X[0].size()[1], self.X[0].size()[2], self.X[0].size()[3], self.X[0].size()[4] ])\n",
    "            self.X=self.X.permute(0,3,1,2,4)\n",
    "\n",
    "        self.X_M=torch.max(self.X)\n",
    "\n",
    "        self.N_ch=self.X.size()[1]\n",
    "        self.T_flow=10\n",
    "        self.alpha=1\n",
    "\n",
    "        self.ema_kernel=torch.zeros([1,self.T_flow,1,1],device=device)\n",
    "        self.ema_kernel[0,:,0,0]=(torch.pow((1-self.alpha),torch.arange(0,self.T_flow))*self.alpha)\n",
    "        \n",
    "        self.Compute_Flow()\n",
    "        \n",
    "        self.Hei=self.X.size()[1]\n",
    "        self.Len=self.X.size()[2]\n",
    "        self.T=self.X.size()[-1]\n",
    "        \n",
    "        \n",
    "        self.X_tr_flow=self.X_flow[0:self.N_tr,...]\n",
    "        self.X_tr=self.X[0:self.N_tr,...]\n",
    "        \n",
    "        self.X_te_flow=self.X_flow[self.N_tr:,...]\n",
    "        self.X_te=self.X[self.N_tr:,...]\n",
    "        \n",
    "        self.Y_tr=self.Y[0:self.N_tr,...]\n",
    "        self.Y_te=self.Y[self.N_tr:,...]\n",
    "\n",
    "        self.A_tr=self.A[0:self.N_tr,...]\n",
    "        self.A_te=self.A[self.N_tr:,...]\n",
    "\n",
    "        self.resolution=self.X_tr.size()[-2]\n",
    "\n",
    "    def Compute_Flow(self):\n",
    "\n",
    "        T=self.X.size()[-1]\n",
    "\n",
    "        self.X_flow=torch.zeros([self.X.size()[0],1,self.X.size()[2],self.X.size()[3],self.X.size()[4]],dtype=torch.uint8)\n",
    "        \n",
    "        for t in range(1,T):\n",
    "\n",
    "            x2=self.X[...,t].to(torch.uint8)/self.X_M\n",
    "            x1=self.X[...,t-1].to(torch.uint8)/self.X_M\n",
    "\n",
    "            delta=(torch.mean(x2-x1,1,keepdim=True))\n",
    "            \n",
    "            self.X_flow[...,t]=(1-self.alpha)*self.X_flow[...,t-1]+self.alpha*(delta+1)/2\n",
    "\n",
    "\n",
    "    def Normalise(self):\n",
    "\n",
    "        self.m=self.Y_tr.mean(0).unsqueeze(0)\n",
    "        self.std=torch.sqrt(self.Y_tr.var(0).unsqueeze(0))\n",
    "        \n",
    "        epsilon=10**(-5)\n",
    "        \n",
    "        self.Y_tr=(self.Y_tr-self.m)/(self.std+epsilon)        \n",
    "        self.Y_te=(self.Y_te-self.m)/(self.std+epsilon)\n",
    "\n",
    "        self.m_a=self.A_tr.mean(0).unsqueeze(0)\n",
    "        self.std_a=torch.sqrt(self.A_tr.var(0).unsqueeze(0))\n",
    "        \n",
    "        self.A_tr=(self.A_tr-self.m_a)/(self.std_a+epsilon)\n",
    "        self.A_te=(self.A_te-self.m_a)/(self.std_a+epsilon)\n",
    "\n",
    "\n",
    "    def Unnormalise(self, Y, Y_true):\n",
    "\n",
    "        Y=Y*(self.std+epsilon)+self.m\n",
    "        Y_true=Y_true*(self.std+epsilon)+self.m\n",
    "\n",
    "        return Y, Y_true\n",
    "    \n",
    "    def Batch(self, batch_size):\n",
    "\n",
    "        rand_ind=torch.randint(0,self.X_tr.size()[0], [batch_size])\n",
    "        rand_t=torch.randint(0,self.X_tr.size()[-1], [batch_size])\n",
    "        \n",
    "        x_batch=self.X_tr[rand_ind,:,:,:,rand_t].float().to(device)/self.X_M\n",
    "        x_batch_flow=self.X_tr_flow[rand_ind,:,:,:,rand_t].float().to(device)\n",
    "        \n",
    "        x_batch=torch.concat([x_batch,x_batch_flow],1)\n",
    "        y_batch=self.Y_tr[rand_ind,:,rand_t].float().to(device)\n",
    "        \n",
    "        return x_batch, y_batch\n",
    "\n",
    "    def Evaluate(self, batch_size_te):\n",
    "\n",
    "        rand_ind=torch.randint(0,self.X_te.size()[0], [batch_size_te])\n",
    "        rand_t=torch.randint(1,self.X_te.size()[-1], [batch_size_te])\n",
    "\n",
    "        x_batch=self.X_te[rand_ind,:,:,:,rand_t].float().to(device)/self.X_M\n",
    "        x_batch_flow=self.X_te_flow[rand_ind,:,:,:,rand_t].float().to(device)\n",
    "        l_batch=self.L[rand_ind,:,:,:,rand_t].to(device)\n",
    "        \n",
    "        x_batch=torch.concat([x_batch,x_batch_flow],1)\n",
    "        y_batch=self.Y_te[rand_ind,:,rand_t].float().to(device)\n",
    "\n",
    "        return x_batch, y_batch, l_batch\n",
    "\n",
    "\n",
    "    def Batch_ODE(self, batch_size, T_horizon):\n",
    "        \n",
    "        A=torch.zeros([batch_size,self.A.size()[1],T_horizon],device=device)\n",
    "        \n",
    "        y=torch.zeros([batch_size,self.Y_tr.size()[1],T_horizon],device=device)\n",
    "        x=torch.zeros([batch_size,T_horizon,self.X_tr.size()[1]+1,self.X_tr.size()[2],self.X_tr.size()[3]],device=device)\n",
    "        \n",
    "        x0s=torch.zeros([batch_size,self.Y_tr.size()[1]],device=device)\n",
    "        \n",
    "        rand_ind=torch.randint(0, self.Y_tr.size()[0], [batch_size])\n",
    "        t_rand=torch.randint(0, self.Y_tr.size()[2]-T_horizon, [batch_size])\n",
    "        \n",
    "        for n in range(batch_size):\n",
    "            \n",
    "            A[n,:,:]=self.A_tr[rand_ind[n],:,t_rand[n]:t_rand[n]+T_horizon].float().to(device)\n",
    "\n",
    "            x[n,:,0:self.N_ch,:,:]=self.X_tr[rand_ind[n],:,:,:,t_rand[n]:t_rand[n]+T_horizon].unsqueeze(0).transpose(-1,0).squeeze().float().to(device)/self.X_M\n",
    "            x[n,:,-1,:,:]=self.X_tr_flow[rand_ind[n],:,:,:,t_rand[n]:t_rand[n]+T_horizon].unsqueeze(0).transpose(-1,0).squeeze().float().to(device)\n",
    "\n",
    "            y[n,:,:]=self.Y_tr[rand_ind[n],:,t_rand[n]:t_rand[n]+T_horizon].float().to(device)\n",
    "            \n",
    "            x0s[n,:]=self.Y_tr[rand_ind[n],:,t_rand[n]].float().to(device)\n",
    "        \n",
    "        t0s=t_rand.to(device)\n",
    "        \n",
    "        return x, y, A, x0s, t0s\n",
    "\n",
    "    def Evaluate_ODE(self, batch_size, T_horizon_val):\n",
    "        \n",
    "        A=torch.zeros([batch_size,self.A_te.size()[1],T_horizon_val],device=device)\n",
    "        \n",
    "        y=torch.zeros([batch_size,self.Y_te.size()[1],T_horizon_val],device=device)\n",
    "        x=torch.zeros([batch_size,T_horizon_val,self.X_te.size()[1]+1,self.X_te.size()[2],self.X_te.size()[3]],device=device)\n",
    "        l=torch.zeros([batch_size,T_horizon_val,self.L.size()[1],self.L.size()[2],self.L.size()[3]],device=device,dtype=torch.uint8)\n",
    "\n",
    "        x0s=torch.zeros([batch_size,self.Y_te.size()[1]],device=device)\n",
    "        \n",
    "        rand_ind=torch.randint(0, self.Y_te.size()[0], [batch_size],device=device)\n",
    "        t_rand=torch.randint(1, self.Y_te.size()[2]-T_horizon_val, [batch_size],device=device)\n",
    "        \n",
    "        for n in range(batch_size):\n",
    "            \n",
    "            A[n,:,:]=self.A_te[rand_ind[n],:,t_rand[n]:t_rand[n]+T_horizon_val].float().to(device)\n",
    "\n",
    "            x[n,:,0:self.N_ch,:,:]=self.X_te[rand_ind[n],:,:,:,t_rand[n]:t_rand[n]+T_horizon_val].unsqueeze(0).transpose(-1,0).squeeze().float().to(device)/self.X_M\n",
    "            x[n,:,-1,:,:]=self.X_te_flow[rand_ind[n],:,:,:,t_rand[n]:t_rand[n]+T_horizon_val].unsqueeze(0).transpose(-1,0).squeeze().float().to(device)\n",
    "            l[n,:,0:self.N_ch,:,:]=self.L[rand_ind[n],:,:,:,t_rand[n]:t_rand[n]+T_horizon_val].unsqueeze(0).transpose(-1,0).squeeze(-1).to(device)\n",
    "            \n",
    "            y[n,:,:]=self.Y_te[rand_ind[n],:,t_rand[n]:t_rand[n]+T_horizon_val].float().to(device)\n",
    "            \n",
    "            x0s[n,:]=self.Y_te[rand_ind[n],:,t_rand[n]].float().to(device)\n",
    "        \n",
    "        t0s=t_rand.to(device)\n",
    "        \n",
    "        return x, y, A, x0s, t0s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655e0787-0b03-455b-bdf3-c0417a8b7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=Data_Manager()\n",
    "\n",
    "batch_size=30\n",
    "T_horizon=50\n",
    "\n",
    "x_batch, y_batch=Data.Batch(batch_size)\n",
    "x_b, y_b, A_b, x0s, t0s=Data.Batch_ODE(batch_size, T_horizon=T_horizon)\n",
    "x_te, y_te, A_te, x0s, t0s, l_te=Data.Evaluate_ODE(batch_size, T_horizon_val=T_horizon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bb64fd7-11e4-460d-aeaf-3a93a0065434",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1, dropout=0.):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(out_ch)\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "        self.conv2=nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "        self.downsample = None\n",
    "        if in_ch != out_ch:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d( in_ch, out_ch, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = self.downsample(x) if self.downsample else x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        out = self.relu(x+identity)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, Ch):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.Ch=Ch\n",
    "        self.First_Block=[]\n",
    "        \n",
    "        self.First_Block.append( nn.Conv2d(Ch[0], Ch[1], kernel_size=3, stride=1, padding=1, bias=False) )\n",
    "        self.First_Block.append( nn.BatchNorm2d(Ch[1]) )\n",
    "        self.First_Block.append( nn.ReLU() )\n",
    "        self.First_Block.append( nn.MaxPool2d(kernel_size=3, stride=2, padding=1) )\n",
    "\n",
    "        self.First_Block=torch.nn.Sequential(*self.First_Block).to(device)\n",
    "        \n",
    "        self.layer=[]\n",
    "        self.layer.append( ResBlock(Ch[1], Ch[2], stride=1) )\n",
    "        \n",
    "        for n in range(3,len(Ch)):\n",
    "\n",
    "            self.layer.append( ResBlock(Ch[n-1], Ch[n], stride=2) ) \n",
    "\n",
    "        self.layer=torch.nn.Sequential(*self.layer).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x=self.First_Block(x)\n",
    "        out=self.layer(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ResBlockTranspose(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1, dropout=0.):\n",
    "        super(ResBlockTranspose, self).__init__()\n",
    "        \n",
    "        self.up = (stride == 2)\n",
    "        \n",
    "        self.conv1 = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=3, stride=stride,\n",
    "                                        padding=1, output_padding=1 if self.up else 0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "        self.upsample = None\n",
    "        if in_ch != out_ch or self.up:\n",
    "            self.upsample = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_ch, out_ch, kernel_size=1, stride=stride,\n",
    "                                   output_padding=1 if self.up else 0, bias=False),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.upsample(x) if self.upsample else x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        out = self.relu(x + identity)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet_Transpose(nn.Module):\n",
    "    def __init__(self, Ch):\n",
    "        super(ResNet_Transpose, self).__init__()\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        # Reverse the channel sequence from encoder: [256, 128, 64, 3]\n",
    "        rev_channels = Ch[::-1]\n",
    "\n",
    "        self.layers.append(ResBlockTranspose(rev_channels[0], rev_channels[1], stride=2))\n",
    "        for i in range(1, len(rev_channels) - 2):\n",
    "            self.layers.append(ResBlockTranspose(rev_channels[i], rev_channels[i+1], stride=2))\n",
    "        \n",
    "        # Final upsample block (optional: back to original resolution)\n",
    "        self.layers.append(nn.ConvTranspose2d(rev_channels[-2], rev_channels[-1],\n",
    "                                              kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        self.net = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ead3b6b-a841-4dbd-bc0e-0578da14d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, resolution, cnn_dim, latent_dim, sensor_dim, CUT=False):\n",
    "        super().__init__()\n",
    "\n",
    "        Chs=[4,16,32,64]\n",
    "        cnn_dim=Chs[-1]\n",
    "\n",
    "        self.encoder_visual_self = ResNet(Chs).to(device)\n",
    "        self.encoder_visual_other = ResNet(Chs).to(device)\n",
    "        \n",
    "        self.latent_dim=latent_dim\n",
    "        self.resolution=resolution\n",
    "\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        \n",
    "        self.project_self = torch.nn.Sequential(nn.Linear(cnn_dim * (resolution // 4) ** 2, 2*latent_dim),\n",
    "                                                nn.ReLU(), \n",
    "                                                nn.Linear(2*latent_dim, latent_dim))\n",
    "        \n",
    "        self.project_other = torch.nn.Sequential(nn.Linear(cnn_dim * (resolution // 4) ** 2, 2*latent_dim),\n",
    "                                                nn.ReLU(), \n",
    "                                                nn.Linear(2*latent_dim, latent_dim))\n",
    "\n",
    "        self.pro2lat=nn.Linear(sensor_dim, latent_dim)\n",
    "                                        \n",
    "        self.CUT=CUT\n",
    "        \n",
    "        if self.CUT:\n",
    "            self.pro2visual=nn.Linear(sensor_dim, latent_dim)\n",
    "                                        \n",
    "            \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            self.pro2lat.weight.zero_()\n",
    "            \n",
    "            if self.CUT:\n",
    "                self.pro2visual.weight.zero_()\n",
    "        \n",
    "            for i in range(sensor_dim):\n",
    "            \n",
    "                self.pro2lat.weight[i,i]=1\n",
    "                \n",
    "                if self.CUT:\n",
    "                    self.pro2visual.weight[i,i]=1\n",
    "\n",
    "    \n",
    "    def forward(self, x, pro_b, path_visual_self, path_visual_other):\n",
    "\n",
    "        batch_size=x.size()[0]\n",
    "        x_visual = x.reshape([batch_size,x.size()[1],self.resolution,self.resolution])\n",
    "        x_visual_self = self.encoder_visual_self(x_visual)  # [B*T, C, H/8, W/8]\n",
    "        x_visual_other = self.encoder_visual_other(x_visual)\n",
    "        \n",
    "        x_visual_self = self.flatten(x_visual_self)  # [B*T, C * H/8 * W/8]\n",
    "        x_visual_other = self.flatten(x_visual_other)\n",
    "\n",
    "        z_self_pro = self.pro2lat(pro_b)\n",
    "\n",
    "        z_self_pro2visual=torch.zeros_like(z_self_pro,device=device)\n",
    "        if self.CUT:    \n",
    "            z_self_pro2visual = self.pro2visual(pro_b)\n",
    "        \n",
    "        z_self_visual=self.project_self(x_visual_self).reshape([batch_size,-1])\n",
    "        \n",
    "        z_other=self.project_other(x_visual_other).reshape([batch_size,-1])*path_visual_other\n",
    "\n",
    "        return z_self_pro, z_self_visual, z_other, z_self_pro2visual\n",
    "\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, resolution, cnn_dim, latent_dim, sensor_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        Chs=[4,16,32,64]\n",
    "        cnn_dim=Chs[-1]\n",
    "        \n",
    "        self.latent_dim=latent_dim\n",
    "        self.resolution=resolution\n",
    "\n",
    "        self.cnn_initial_size = (resolution // 4, resolution // 4)\n",
    "\n",
    "        # Latent to feature map\n",
    "        self.cnn_dim=cnn_dim\n",
    "\n",
    "        self.project_self = torch.nn.Sequential(nn.Linear(latent_dim, 2*latent_dim),\n",
    "                                                nn.ReLU(), \n",
    "                                                nn.Linear(2*latent_dim, cnn_dim * self.cnn_initial_size[0] * self.cnn_initial_size[1]))\n",
    "        \n",
    "        self.project_other = torch.nn.Sequential(nn.Linear(latent_dim, 2*latent_dim),\n",
    "                                                nn.ReLU(), \n",
    "                                                nn.Linear(2*latent_dim, cnn_dim * self.cnn_initial_size[0] * self.cnn_initial_size[1]))\n",
    "\n",
    "        self.lat2pro=torch.nn.Sequential(nn.Linear(latent_dim, latent_dim),\n",
    "                                                nn.ReLU(), \n",
    "                                                nn.Linear(latent_dim, latent_dim),\n",
    "                                                nn.ReLU(),\n",
    "                                                nn.Linear(latent_dim, sensor_dim)       \n",
    "                                        )                    \n",
    "        self.decoder_visual_self=ResNet_Transpose(Chs)\n",
    "        self.decoder_visual_other=ResNet_Transpose(Chs)\n",
    "\n",
    "        \n",
    "    def forward(self, z_self, z_other):\n",
    "        \n",
    "        B = z_self.size(0)\n",
    "\n",
    "        pro_rec=self.lat2pro(z_self)\n",
    "        \n",
    "        x_self = self.project_self(z_self)\n",
    "        x_other = self.project_other(z_other)\n",
    "        \n",
    "        x_self = x_self.view(B, self.cnn_dim, *self.cnn_initial_size)\n",
    "        x_other = x_other.view(B, self.cnn_dim, *self.cnn_initial_size)\n",
    "\n",
    "        x_self=self.decoder_visual_self(x_self.reshape([B,self.cnn_dim,*self.cnn_initial_size]))\n",
    "        x_other=self.decoder_visual_other(x_other.reshape([B,self.cnn_dim,*self.cnn_initial_size]))\n",
    "\n",
    "        \n",
    "        mask_self = torch.mean(x_self[:, 0:3:, :self.resolution, :self.resolution],1,keepdim=True) \n",
    "        mask_self = torch.sigmoid((mask_self-0.5))\n",
    "        \n",
    "        mask_other = x_other[:, -1:, :self.resolution, :self.resolution]\n",
    "        \n",
    "        mask_other = ((1 - mask_self).detach())\n",
    "        \n",
    "        x_self = x_self[:, 0:-1, :self.resolution, :self.resolution]  # Crop if needed\n",
    "        x_other = x_other[:, 0:-1, :self.resolution, :self.resolution]  # Crop if needed\n",
    "        \n",
    "        img_self = x_self * mask_self\n",
    "        img_other = x_other * mask_other\n",
    "\n",
    "        return img_self, img_other, mask_self, mask_other, pro_rec\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a22c85ea-049f-48b5-9090-0e94e39d34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODE_IntMethods:\n",
    "    \n",
    "    def __init__(self,F,dt):\n",
    "        \n",
    "        self.dt=dt\n",
    "        self.F=F.to(device)\n",
    "        self.device=device\n",
    "    \n",
    "    \n",
    "    def RK2(self,X,I,t):\n",
    "        \n",
    "        k1=self.F(X,t,I)\n",
    "        k2=self.F(X+k1*self.dt,t+self.dt,I)\n",
    "        x_new=X+1/2*(k1+k2)*self.dt\n",
    "        \n",
    "        return x_new\n",
    "    \n",
    "\n",
    "    def RK4(self,X,I,t):\n",
    "        \n",
    "        k1=self.F(X,t,I)\n",
    "        k2=self.F(X+k1*self.dt/2,t+self.dt/2,I)\n",
    "        k3=self.F(X+k2*self.dt/2,t+self.dt/2,I)\n",
    "        k4=self.F(X+k3*self.dt,t+self.dt,I)\n",
    "        x_new=X+1/6*(k1+2*k2+2*k3+k4)*self.dt\n",
    "        \n",
    "        return x_new\n",
    "    \n",
    "    def Compute_Dynamics(self,Input,x0,t0):\n",
    "        \n",
    "        T=Input.size()[2]\n",
    "        batch_size=x0.size()[0]\n",
    "        N=x0.size()[1]\n",
    "        \n",
    "        X=torch.zeros([batch_size,N,T],device=device)\n",
    "        X[:,:,0]=x0\n",
    "        \n",
    "        t=t0\n",
    "        \n",
    "        for n in range(1,T):\n",
    "            \n",
    "            if Input!=[]:\n",
    "                I=Input[:,:,n]\n",
    "\n",
    "            X[:,:,n]=self.RK4(X[:,:,n-1],I,t)\n",
    "                    \n",
    "            \n",
    "        return X\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self,F_Ns):\n",
    "        super().__init__()\n",
    "                \n",
    "        module=[]\n",
    "        \n",
    "        for n in range(1,F_Ns.size()[0]):\n",
    "                        \n",
    "            module.append(nn.Linear(F_Ns[n-1],F_Ns[n]))\n",
    "        \n",
    "            if n<F_Ns.size()[0]-1:\n",
    "            \n",
    "                module.append(nn.ReLU())\n",
    "                \n",
    "        self.F=nn.Sequential(*module)\n",
    "        \n",
    "        self.F_Ns=F_Ns\n",
    "                    \n",
    "    def forward(self,X,t=[],S=[]):\n",
    "        \n",
    "        if S!=[]:\n",
    "            \n",
    "            Input=torch.concat([X,S],1)\n",
    "            \n",
    "        else:\n",
    "            Input=X\n",
    "            \n",
    "        y=self.F(Input)\n",
    "        \n",
    "        return y\n",
    "\n",
    "\n",
    "class Model_ODE(nn.Module):\n",
    "    \n",
    "    def __init__(self, F_Ns, dt):\n",
    "        super().__init__()    \n",
    "        \n",
    "        self.F_Ns=F_Ns\n",
    "        \n",
    "        self.dt=dt\n",
    "        self.f=MLP(F_Ns).to(device)\n",
    "        self.F=ODE_IntMethods(self.f,dt)\n",
    "                    \n",
    "            \n",
    "    def Reset(self,Input,t0s):\n",
    "        \n",
    "        self.X=Input\n",
    "        self.t=t0s\n",
    "        \n",
    "    def ODE_step(self,Input):\n",
    "        \n",
    "        self.X=self.F.RK2(self.X,Input,self.t)\n",
    "        self.t=self.t+self.dt\n",
    "    \n",
    "    def forward(self,Input,y_true,X0s,t0s):\n",
    "        \n",
    "        T=y_true.size()[2]\n",
    "        batch_size=y_true.size()[0]\n",
    "        \n",
    "        y=torch.zeros([batch_size,y_true.size()[1],T],device=device)\n",
    "        \n",
    "        err=0\n",
    "    \n",
    "        self.Reset(X0s,t0s)\n",
    "        \n",
    "        y[:,:,0]=X0s.clone()\n",
    "        \n",
    "        I=Input\n",
    "        \n",
    "        for t in range(1,T):\n",
    "            \n",
    "            \n",
    "            if Input!=[]:\n",
    "            \n",
    "                self.ODE_step(I[:,:,t-1])\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                self.ODE_step([])\n",
    "                \n",
    "            \n",
    "            y[:,:,t]=self.X.clone()\n",
    "                \n",
    "        err=torch.mean((y_true[:,:,1:]-y[:,:,1:])**2,[0,1])\n",
    "        \n",
    "        return err, y\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "535b3679-f170-4869-834d-779f8e1c3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import rgb_to_grayscale\n",
    "\n",
    "def to_grayscale_batch(x):\n",
    "    \n",
    "    \"\"\"\n",
    "    x: [B, C, H, W], C in {1, 3}. dtype uint8 or float.\n",
    "    Returns: [B, 1, H, W] float32 in [0, 1].\n",
    "    \"\"\"\n",
    "    if x.dtype == torch.uint8:\n",
    "        x = x.float() / 255.0  # normalize; keeps device (CPU/GPU)\n",
    "    if x.ndim != 4 or x.size(1) not in (1, 3):\n",
    "        raise ValueError(f\"Expected [B, C, H, W] with C=1 or 3, got {tuple(x.shape)}\")\n",
    "\n",
    "    # If already single-channel, pass through; otherwise convert RGB->gray\n",
    "    y = x if x.size(1) == 1 else rgb_to_grayscale(x)  # -> [B, 1, H, W]\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "593b6b82-36b7-4e47-8700-234c2f16f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "        \n",
    "\n",
    "class Self_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, resolution, cnn_dim, latent_dim, sensor_dim, \\\n",
    "                 F_Ns, dt, RK=2):             ## PREDICTIVE HYPER\n",
    "        super().__init__()    \n",
    "\n",
    "        self.latent_dim=latent_dim\n",
    "        self.cnn_dim=cnn_dim\n",
    "        self.sensor_dim=sensor_dim\n",
    "        \n",
    "        ## CORRELATION\n",
    "        self.encoder=Encoder(resolution, cnn_dim, latent_dim, sensor_dim).to(device)\n",
    "        self.decoder=Decoder(resolution, cnn_dim, latent_dim, sensor_dim).to(device)\n",
    "        self.opt=optim.Adam( list(self.encoder.parameters())+list(self.decoder.parameters()), lr=0.001)\n",
    "        \n",
    "        \n",
    "        ## PREDICTIVE\n",
    "        self.Predictive=Model_ODE(F_Ns, dt)\n",
    "        self.opt_Predictive=optim.Adam(list(self.Predictive.F.F.parameters()), lr=0.001)\n",
    "\n",
    "\n",
    "    def Override_Predictive(self, F_Ns, dt, lr):\n",
    "\n",
    "        self.Predictive=Model_ODE(F_Ns, dt)\n",
    "        self.opt_Predictive=optim.Adam(list(self.Predictive.F.F.parameters())+list(self.decoder.lat2pro.parameters()), lr=0.001)\n",
    "\n",
    "    def Accuracy(self, img, lab, self_acc=True):\n",
    "\n",
    "\n",
    "        mask=to_grayscale_batch(img)\n",
    "        \n",
    "        b=img_self.size()[0]\n",
    "        tot_ind=128*128\n",
    "\n",
    "        if self_acc:\n",
    "            \n",
    "            lab=(lab==1).reshape([b, -1])\n",
    "            ind_sum=torch.sum( lab.float(), 1)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            lab=(lab>1).reshape([b, -1])\n",
    "            ind_sum=torch.sum( lab.float(), 1)\n",
    "\n",
    "        m=mask.reshape([b,-1])\n",
    "        \n",
    "        ind_sort=torch.sort(m,1)[1]\n",
    "        ind_sort_lab=torch.sort(lab.float(),1)[1]\n",
    "        \n",
    "        max_k = int(ind_sum.max().item())\n",
    "        topk   = ind_sort[:, -max_k:]                                        # [B, max_k]\n",
    "        topk_lab = ind_sort_lab[:, -max_k:]\n",
    "        valid  = torch.arange(max_k, device=device).unsqueeze(0) < ind_sum.unsqueeze(1)  # [B, max_k]\n",
    "        \n",
    "        \n",
    "        mask_flat = torch.zeros(b, m.size()[1], dtype=torch.bool, device=device)   # or dtype=torch.float32\n",
    "        mask_flat_lab = torch.zeros(b, m.size()[1], dtype=torch.bool, device=device)\n",
    "        \n",
    "        rows = torch.arange(b, device=device).unsqueeze(1).expand(-1, max_k)\n",
    "        mask_flat[rows[valid], topk[valid]] = True  \n",
    "        mask_flat_lab[rows[valid], topk_lab[valid]] = True \n",
    "        \n",
    "        norm=(mask_flat_lab*lab).float().sum()/(torch.tensor([ind_sum.max()*b, mask_flat_lab.sum()]).min())\n",
    "        acc=(mask_flat*lab).float().sum()/(torch.tensor([ind_sum.max()*b, mask_flat.sum()]).min())/norm\n",
    "        \n",
    "        \n",
    "        return acc\n",
    "        \n",
    "    \n",
    "    def Correlation_forward(self,x_b, pro_b, x_b_pred, pro_b_pred, A_b_pred, x0s, t0s, n, TRAIN=True, PRO=0, eta_consistency=0.5):\n",
    "\n",
    "        batch_size=x_b.size()[0]\n",
    "\n",
    "        if n<10000:\n",
    "            \n",
    "            path_visual_self=torch.rand([batch_size,1],device=device)\n",
    "            path_visual_other=torch.zeros([batch_size,1],device=device)\n",
    "            path_visual_ot=0.\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            path_visual_self=torch.rand([batch_size,1],device=device)\n",
    "            path_visual_other=torch.ones([batch_size,1],device=device)\n",
    "            path_visual_ot=1.\n",
    "            \n",
    "            \n",
    "        \n",
    "        z_self_pro, z_self_visual, z_other, z_self_pro2visual=self.encoder(x_b, pro_b*0, path_visual_self, path_visual_other)\n",
    "        z_self=(1-path_visual_self)*z_self_pro+path_visual_self*z_self_visual\n",
    "        img_self, img_other, mask_self, mask_other, pro_rec = self.decoder(z_self,z_other)\n",
    "        \n",
    "        if n<10000:\n",
    "            \n",
    "            img = (img_self + img_other.detach())\n",
    "            \n",
    "        else:\n",
    "\n",
    "            img = (img_self + img_other)\n",
    "\n",
    "        consistency_loss1=torch.zeros([1], device=device)\n",
    "        \n",
    "        if PRO==1:\n",
    "            Z_, X0s=self.Correlation(x_b_pred, pro_b_pred)\n",
    "            consistency_loss1 = torch.mean(torch.pow(Z_[:,0:self.latent_dim,1:]-Z_[:,0:self.latent_dim,0:-1],2))\n",
    "        \n",
    "        recon_loss1 = torch.mean(torch.abs(img-x_b[:,0:-1,:,:]))\n",
    "\n",
    "        if self.encoder.CUT:\n",
    "            joint_loss1 = torch.mean(torch.pow(z_self_pro2visual-z_self_visual,2))\n",
    "        else:\n",
    "            joint_loss1=torch.zeros([1],device=device)\n",
    "            \n",
    "        recon_pro_loss1 = torch.mean(torch.pow(pro_rec-pro_b,2))\n",
    "        \n",
    "        err = recon_loss1  + 0.5*joint_loss1 + recon_pro_loss1 + eta_consistency*consistency_loss1\n",
    "\n",
    "        \n",
    "        if TRAIN:\n",
    "            \n",
    "            err.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "            self.opt_Predictive.zero_grad()\n",
    "\n",
    "        return recon_loss1.detach(), joint_loss1.detach(), recon_pro_loss1.detach(), consistency_loss1.detach(),\\\n",
    "        z_self.detach(), z_other.detach(), img.detach(), img_self.detach(), img_other.detach(), mask_self.detach(), mask_other.detach()\n",
    "\n",
    "\n",
    "    def Correlation_Eval(self,x_b, pro_b, x_b_pred, pro_b_pred, A_b_pred, x0s, t0s, n, lab, TRAIN=True, PRO=0):\n",
    "\n",
    "        batch_size=x_b.size()[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            path_visual_self=torch.rand([batch_size,1],device=device)\n",
    "            \n",
    "            if n<10000:\n",
    "                path_visual_other=torch.zeros([batch_size,1],device=device)\n",
    "                path_visual_ot=0.\n",
    "            else:\n",
    "                path_visual_other=torch.ones([batch_size,1],device=device)\n",
    "                path_visual_ot=1.\n",
    "                \n",
    "            z_self_pro, z_self_visual, z_other, z_self_pro2visual=self.encoder(x_b, pro_b, path_visual_self, path_visual_other)\n",
    "            z_self_mixed=(1-path_visual_self)*z_self_pro+path_visual_self*z_self_visual\n",
    "\n",
    "            consistency_loss=torch.zeros([1], device=device)\n",
    "            if PRO==1:\n",
    "                Z_, X0s=self.Correlation(x_b_pred, pro_b_pred)\n",
    "                consistency_loss = torch.mean(torch.pow(Z_[:,0:self.latent_dim,1:]-Z_[:,0:self.latent_dim,0:-1],2))\n",
    "                \n",
    "        \n",
    "            img_self_mixed, img_other_mixed, mask_self_mixed, mask_other_mixed, pro_rec = self.decoder(z_self_mixed,z_other)\n",
    "            \n",
    "            img_mixed = img_self_mixed + img_other_mixed\n",
    "            \n",
    "            recon_loss_mixed = torch.mean(torch.abs(img_mixed-x_b[:,0:-1,:,:]))\n",
    "\n",
    "            acc_self_mixed=self.Accuracy(img_self_mixed,lab,self_acc=True)\n",
    "            acc_other_mixed=self.Accuracy(img_other_mixed,lab,self_acc=False)\n",
    "            \n",
    "            if self.encoder.CUT:\n",
    "                \n",
    "                joint_loss = torch.mean(torch.pow(z_self_pro2visual-z_self_visual,2))\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                joint_loss=torch.zeros([1],device=device)\n",
    "            \n",
    "            recon_pro_loss = torch.mean(torch.pow(pro_rec-pro_b,2))\n",
    "    \n",
    "            \n",
    "            img_self_visual, img_other_visual, mask_self_visual, mask_other_visual, _ = self.decoder(z_self_visual,z_other)\n",
    "            img_visual = img_self_visual + img_other_visual\n",
    "    \n",
    "            recon_loss_visual = torch.mean(torch.abs(img_visual-x_b[:,0:-1,:,:]))\n",
    "\n",
    "            acc_self_visual=self.Accuracy(img_self_visual,lab,self_acc=True)\n",
    "            acc_other_visual=self.Accuracy(img_other_visual,lab,self_acc=False)\n",
    "            \n",
    "            \n",
    "            img_self_pro, img_other_pro, mask_self_pro, mask_other_pro, _ = self.decoder(z_self_pro,z_other)\n",
    "            img_pro = img_self_pro + img_other_pro\n",
    "\n",
    "            acc_self_pro=self.Accuracy(img_self_pro,lab,self_acc=True)\n",
    "            acc_other_pro=self.Accuracy(img_other_pro,lab,self_acc=False)\n",
    "            \n",
    "            recon_loss_pro = torch.mean(torch.abs(img_pro-x_b[:,0:-1,:,:]))\n",
    "    \n",
    "            cosine_pro=F.cosine_similarity(z_self_pro, z_self_mixed, dim=1).mean(0)\n",
    "            cosine_visual=F.cosine_similarity(z_self_visual, z_self_mixed, dim=1).mean(0)\n",
    "            cosine_vp=F.cosine_similarity(z_self_pro, z_self_visual, dim=1).mean(0)\n",
    "\n",
    "        \n",
    "        return recon_loss_mixed.detach(),  recon_loss_visual.detach(),  \\\n",
    "        recon_loss_pro.detach(), joint_loss.detach(), recon_pro_loss.detach(), consistency_loss.detach(), \\\n",
    "        acc_self_mixed.detach(), acc_other_mixed.detach(), acc_self_pro.detach(), acc_other_pro.detach(), acc_self_visual.detach(), acc_other_visual.detach(), \\\n",
    "        img_mixed.detach(), img_self_mixed.detach(), img_other_mixed.detach(), mask_self_mixed.detach(), mask_other_mixed.detach(), \\\n",
    "        img_visual.detach(), img_self_visual.detach(), img_other_visual.detach(), mask_self_visual.detach(), mask_other_visual.detach(), \\\n",
    "        img_pro.detach(), img_self_pro.detach(), img_other_pro.detach(), mask_self_pro.detach(), mask_other_pro.detach(), \\\n",
    "        cosine_pro.detach(), cosine_visual.detach(), cosine_vp.detach()\n",
    "            \n",
    "    \n",
    "    def Correlation(self, x_b, pro_b):\n",
    "        \n",
    "        T_hor=x_b.size()[1]\n",
    "        batch_size=x_b.size()[0]\n",
    "        x_b=x_b.view([batch_size*T_hor,x_b.size()[2],x_b.size(3),x_b.size(4)])\n",
    "        pro_b=pro_b.transpose(-1,-2).reshape([batch_size*T_hor,-1])\n",
    "\n",
    "        path_visual_self=torch.tile(torch.rand([batch_size,1,1],device=device),[1,T_hor,1]).reshape([batch_size*T_hor,-1])\n",
    "        path_visual_other=torch.ones([batch_size*T_hor,1],device=device)\n",
    "           \n",
    "        z_self_pro, z_self_visual, z_other, z_self_pro2visual=self.encoder(x_b, pro_b, path_visual_self, path_visual_other)\n",
    "            \n",
    "        z_=(1-path_visual_self)*z_self_pro+path_visual_self*z_self_visual\n",
    "        \n",
    "        z_b=z_.view([batch_size, T_hor, z_.size()[1]]).transpose(-1,-2)\n",
    "        X0s=z_b[...,0]\n",
    "        \n",
    "        return z_b, X0s\n",
    "\n",
    "    def Predictive_forward(self,x_b,y_b,A_b,t0s,TRAIN=True):\n",
    "\n",
    "        T_decode=5\n",
    "        T=x_b.size()[1]\n",
    "\n",
    "        Ts=int(np.floor(T/T_decode))*torch.arange(0,5)\n",
    "        Ts[-1]=T-1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            Z_, X0s=self.Correlation(x_b, y_b)\n",
    "\n",
    "        err_latent,Z_recon=self.Predictive.forward(A_b,Z_,X0s,t0s)\n",
    "        img_self=torch.zeros([1],device=device)\n",
    "        \n",
    "        if TRAIN==False:\n",
    "            \n",
    "            Z_decode=Z_recon[:,:,Ts]\n",
    "            batch_size=Z_decode.size()[0]\n",
    "            Z_decode=Z_decode.transpose(-1,-2).reshape([batch_size*T_decode, -1])\n",
    "\n",
    "            B=batch_size*T_decode\n",
    "            x_self = self.decoder.project_self(Z_decode)\n",
    "            x_self = x_self.view(B, self.decoder.cnn_dim, *self.decoder.cnn_initial_size)\n",
    "            x_self=self.decoder.decoder_visual_self(x_self.reshape([B,self.decoder.cnn_dim,*self.decoder.cnn_initial_size]))\n",
    "            \n",
    "            mask_self = torch.mean(x_self[:, 0:3:, :self.decoder.resolution, :self.decoder.resolution],1,keepdim=True) \n",
    "            mask_self = torch.sigmoid(mask_self)\n",
    "            \n",
    "            x_self = x_self[:, 0:-1, :self.decoder.resolution, :self.decoder.resolution]  # Crop if needed\n",
    "            \n",
    "            img_self = x_self * mask_self\n",
    "            img_self = img_self.reshape([batch_size,T_decode,img_self.size()[1],img_self.size()[2],img_self.size()[3]])\n",
    "\n",
    "        Y_recon=self.decoder.lat2pro(Z_recon[:,0:self.latent_dim,:].transpose(-2,-1)).transpose(-2,-1)\n",
    "        \n",
    "        err_original=torch.pow(Y_recon-y_b,2).mean([0,1])\n",
    "        err=err_latent.mean()+err_original.mean()\n",
    "\n",
    "\n",
    "        if TRAIN:\n",
    "            \n",
    "            err.backward()\n",
    "            self.opt_Predictive.step()\n",
    "            self.opt.zero_grad()\n",
    "            self.opt_Predictive.zero_grad()\n",
    "\n",
    "        return err_original.detach(), err_latent.detach(), Z_recon.detach(), Y_recon.detach(), Z_.detach(), img_self.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c298ae6-6357-4825-9095-d51815704d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution=128\n",
    "cnn_dim=32 \n",
    "\n",
    "latent_dim=100 \n",
    "sensor_dim=76\n",
    "\n",
    "\n",
    "eta=0.001\n",
    "\n",
    "X_DIM=latent_dim+latent_dim\n",
    "S_DIM=Data.A.size()[1]\n",
    "F_Ns=torch.tensor([latent_dim+A_b.size()[1],200,200,latent_dim])\n",
    "dt=0.1\n",
    "dt=torch.tensor(dt).float()\n",
    "\n",
    "self_model=Self_Model(resolution, cnn_dim, latent_dim, sensor_dim, \\\n",
    "                 F_Ns, dt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51b0727-4801-4b35-89e1-2d94de168497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Err Tr:  tensor([1.1923, 0.1211, 0.0000, 0.6845])\n",
      "0 Err Te:  tensor([1.1215, 1.1409, 1.1321, 0.0000, 1.8920, 0.0833])\n",
      "0 Cosines:  tensor([ 0.0778,  0.9591, -0.0578])\n",
      "0 ACC:  tensor([0.4094, 0.0323, 0.4146, 0.0320, 0.4064, 0.0331])\n",
      "600 Err Tr:  tensor([nan, nan, nan, nan])\n",
      "600 Err Te:  tensor([0.1431, 0.1206, 0.2485, 0.0000, 0.5647, 0.1067])\n",
      "600 Cosines:  tensor([ 0.3860,  0.8242, -0.0066])\n",
      "600 ACC:  tensor([0.7110, 0.0359, 0.7405, 0.0360, 0.5761, 0.0357])\n",
      "1200 Err Tr:  tensor([0.1085, 0.1067, 0.0000, 0.5189])\n",
      "1200 Err Te:  tensor([0.1373, 0.1041, 0.2539, 0.0000, 0.5002, 0.1764])\n",
      "1200 Cosines:  tensor([ 0.4392,  0.7444, -0.0361])\n",
      "1200 ACC:  tensor([0.7202, 0.0357, 0.7603, 0.0357, 0.5746, 0.0355])\n",
      "1800 Err Tr:  tensor([0.1038, 0.1077, 0.0000, 0.5160])\n",
      "1800 Err Te:  tensor([0.1245, 0.0968, 0.2635, 0.0000, 0.5238, 0.1017])\n",
      "1800 Cosines:  tensor([ 0.3204,  0.7991, -0.0949])\n",
      "1800 ACC:  tensor([0.7139, 0.0354, 0.7522, 0.0353, 0.5301, 0.0354])\n",
      "2400 Err Tr:  tensor([0.1004, 0.1086, 0.0000, 0.5113])\n",
      "2400 Err Te:  tensor([0.1238, 0.0912, 0.2649, 0.0000, 0.4970, 0.2470])\n",
      "2400 Cosines:  tensor([ 0.3934,  0.7626, -0.0804])\n",
      "2400 ACC:  tensor([0.7196, 0.0360, 0.7637, 0.0361, 0.5478, 0.0357])\n",
      "3000 Err Tr:  tensor([0.0980, 0.1101, 0.0000, 0.5062])\n",
      "3000 Err Te:  tensor([0.1306, 0.0855, 0.2775, 0.0000, 0.5272, 0.0749])\n",
      "3000 Cosines:  tensor([ 0.3828,  0.7252, -0.1176])\n",
      "3000 ACC:  tensor([0.7079, 0.0352, 0.7598, 0.0351, 0.5346, 0.0350])\n",
      "3600 Err Tr:  tensor([0.0962, 0.1101, 0.0000, 0.5035])\n",
      "3600 Err Te:  tensor([0.1177, 0.0870, 0.2720, 0.0000, 0.4429, 0.0929])\n",
      "3600 Cosines:  tensor([ 0.2982,  0.7840, -0.1347])\n",
      "3600 ACC:  tensor([0.7144, 0.0356, 0.7534, 0.0359, 0.5293, 0.0349])\n",
      "4200 Err Tr:  tensor([0.0947, 0.1111, 0.0000, 0.4998])\n",
      "4200 Err Te:  tensor([0.1326, 0.0894, 0.2860, 0.0000, 0.4718, 0.1526])\n",
      "4200 Cosines:  tensor([ 0.3418,  0.7489, -0.1395])\n",
      "4200 ACC:  tensor([0.7049, 0.0343, 0.7639, 0.0345, 0.5339, 0.0341])\n",
      "4800 Err Tr:  tensor([0.0935, 0.1122, 0.0000, 0.4970])\n",
      "4800 Err Te:  tensor([0.1215, 0.0865, 0.2849, 0.0000, 0.5099, 0.0975])\n",
      "4800 Cosines:  tensor([ 0.3133,  0.7653, -0.1525])\n",
      "4800 ACC:  tensor([0.7037, 0.0356, 0.7553, 0.0358, 0.5095, 0.0350])\n",
      "5400 Err Tr:  tensor([0.0925, 0.1133, 0.0000, 0.4956])\n",
      "5400 Err Te:  tensor([0.1247, 0.0848, 0.2792, 0.0000, 0.5417, 0.0709])\n",
      "5400 Cosines:  tensor([ 0.3691,  0.7421, -0.1294])\n",
      "5400 ACC:  tensor([0.6975, 0.0353, 0.7527, 0.0355, 0.5017, 0.0350])\n",
      "6000 Err Tr:  tensor([0.0917, 0.1145, 0.0000, 0.4936])\n",
      "6000 Err Te:  tensor([0.1390, 0.0856, 0.2883, 0.0000, 0.5004, 0.1000])\n",
      "6000 Cosines:  tensor([ 0.3909,  0.7097, -0.1327])\n",
      "6000 ACC:  tensor([0.6795, 0.0356, 0.7590, 0.0358, 0.5024, 0.0351])\n",
      "6600 Err Tr:  tensor([0.0910, 0.1158, 0.0000, 0.4911])\n",
      "6600 Err Te:  tensor([0.1273, 0.0860, 0.2936, 0.0000, 0.4443, 0.0809])\n",
      "6600 Cosines:  tensor([ 0.3606,  0.7389, -0.1303])\n",
      "6600 ACC:  tensor([0.7120, 0.0351, 0.7688, 0.0352, 0.5286, 0.0347])\n",
      "7200 Err Tr:  tensor([0.0903, 0.1169, 0.0000, 0.4884])\n",
      "7200 Err Te:  tensor([0.1275, 0.0869, 0.2863, 0.0000, 0.4756, 0.1530])\n",
      "7200 Cosines:  tensor([ 0.3859,  0.7431, -0.1155])\n",
      "7200 ACC:  tensor([0.6992, 0.0357, 0.7608, 0.0360, 0.5190, 0.0351])\n",
      "7800 Err Tr:  tensor([0.0898, 0.1179, 0.0000, 0.4862])\n",
      "7800 Err Te:  tensor([0.1276, 0.0858, 0.2911, 0.0000, 0.5020, 0.1330])\n",
      "7800 Cosines:  tensor([ 0.3344,  0.7588, -0.1348])\n",
      "7800 ACC:  tensor([0.7048, 0.0353, 0.7664, 0.0356, 0.5094, 0.0348])\n",
      "8400 Err Tr:  tensor([0.0894, 0.1190, 0.0000, 0.4837])\n",
      "8400 Err Te:  tensor([0.1527, 0.0847, 0.3029, 0.0000, 0.6053, 0.1970])\n",
      "8400 Cosines:  tensor([ 0.3065,  0.7665, -0.1537])\n",
      "8400 ACC:  tensor([0.6739, 0.0350, 0.7692, 0.0354, 0.5237, 0.0346])\n",
      "9000 Err Tr:  tensor([0.0889, 0.1204, 0.0000, 0.4817])\n",
      "9000 Err Te:  tensor([0.1335, 0.0801, 0.2914, 0.0000, 0.5921, 0.1197])\n",
      "9000 Cosines:  tensor([ 0.3373,  0.7708, -0.1091])\n",
      "9000 ACC:  tensor([0.6798, 0.0352, 0.7583, 0.0356, 0.5015, 0.0348])\n",
      "9600 Err Tr:  tensor([0.0886, 0.1215, 0.0000, 0.4803])\n",
      "9600 Err Te:  tensor([0.1276, 0.0842, 0.2969, 0.0000, 0.5241, 0.3779])\n",
      "9600 Cosines:  tensor([ 0.3434,  0.7589, -0.1292])\n",
      "9600 ACC:  tensor([0.6907, 0.0344, 0.7572, 0.0346, 0.4962, 0.0339])\n",
      "10200 Err Tr:  tensor([0.0884, 0.1231, 0.0000, 0.4786])\n",
      "10200 Err Te:  tensor([0.1123, 0.0785, 0.2622, 0.0000, 0.5027, 0.1981])\n",
      "10200 Cosines:  tensor([ 0.3433,  0.7570, -0.1311])\n",
      "10200 ACC:  tensor([0.8174, 0.0468, 0.8825, 0.0470, 0.5269, 0.0458])\n",
      "10800 Err Tr:  tensor([0.0877, 0.1246, 0.0000, 0.4765])\n",
      "10800 Err Te:  tensor([0.1122, 0.0729, 0.2545, 0.0000, 0.4941, 0.1566])\n",
      "10800 Cosines:  tensor([ 0.3123,  0.7824, -0.1345])\n",
      "10800 ACC:  tensor([0.8536, 0.0576, 0.9155, 0.0581, 0.5415, 0.0560])\n",
      "11400 Err Tr:  tensor([0.0869, 0.1260, 0.0000, 0.4746])\n",
      "11400 Err Te:  tensor([0.1036, 0.0736, 0.2452, 0.0000, 0.4755, 0.1169])\n",
      "11400 Cosines:  tensor([ 0.2805,  0.7960, -0.1546])\n",
      "11400 ACC:  tensor([0.8769, 0.0700, 0.9287, 0.0688, 0.5493, 0.0675])\n",
      "12000 Err Tr:  tensor([0.0861, 0.1278, 0.0000, 0.4726])\n",
      "12000 Err Te:  tensor([0.1170, 0.0696, 0.2438, 0.0000, 0.5258, 0.1225])\n",
      "12000 Cosines:  tensor([ 0.3510,  0.7492, -0.1260])\n",
      "12000 ACC:  tensor([0.8696, 0.0745, 0.9366, 0.0731, 0.5625, 0.0734])\n",
      "12600 Err Tr:  tensor([0.0852, 0.1295, 0.0000, 0.4704])\n",
      "12600 Err Te:  tensor([0.1062, 0.0679, 0.2377, 0.0000, 0.5185, 0.1734])\n",
      "12600 Cosines:  tensor([ 0.3424,  0.7578, -0.1205])\n",
      "12600 ACC:  tensor([0.8709, 0.0777, 0.9372, 0.0771, 0.5531, 0.0752])\n",
      "13200 Err Tr:  tensor([0.0844, 0.1311, 0.0000, 0.4683])\n",
      "13200 Err Te:  tensor([0.1090, 0.0682, 0.2352, 0.0000, 0.5307, 0.1782])\n",
      "13200 Cosines:  tensor([ 0.3235,  0.7713, -0.1148])\n",
      "13200 ACC:  tensor([0.8728, 0.0850, 0.9339, 0.0832, 0.5603, 0.0805])\n",
      "13800 Err Tr:  tensor([0.0835, 0.1326, 0.0000, 0.4663])\n",
      "13800 Err Te:  tensor([0.1013, 0.0645, 0.2272, 0.0000, 0.5273, 0.1862])\n",
      "13800 Cosines:  tensor([ 0.3342,  0.7653, -0.1241])\n",
      "13800 ACC:  tensor([0.8784, 0.0881, 0.9398, 0.0872, 0.5740, 0.0806])\n",
      "14400 Err Tr:  tensor([0.0827, 0.1344, 0.0000, 0.4646])\n",
      "14400 Err Te:  tensor([0.0934, 0.0648, 0.2295, 0.0000, 0.5012, 0.1667])\n",
      "14400 Cosines:  tensor([ 0.3142,  0.7822, -0.1091])\n",
      "14400 ACC:  tensor([0.8930, 0.0826, 0.9457, 0.0825, 0.6081, 0.0715])\n",
      "15000 Err Tr:  tensor([0.0820, 0.1359, 0.0000, 0.4627])\n",
      "15000 Err Te:  tensor([0.0923, 0.0631, 0.2263, 0.0000, 0.5508, 0.1316])\n",
      "15000 Cosines:  tensor([ 0.3309,  0.7783, -0.1132])\n",
      "15000 ACC:  tensor([0.8893, 0.0644, 0.9454, 0.0633, 0.6002, 0.0510])\n",
      "15600 Err Tr:  tensor([0.0812, 0.1374, 0.0000, 0.4609])\n",
      "15600 Err Te:  tensor([0.0885, 0.0631, 0.2251, 0.0000, 0.4927, 0.1648])\n",
      "15600 Cosines:  tensor([ 0.3173,  0.7930, -0.1008])\n",
      "15600 ACC:  tensor([0.8934, 0.0542, 0.9450, 0.0558, 0.5840, 0.0420])\n",
      "16200 Err Tr:  tensor([0.0805, 0.1387, 0.0000, 0.4592])\n",
      "16200 Err Te:  tensor([0.0875, 0.0593, 0.2286, 0.0000, 0.4963, 0.1484])\n",
      "16200 Cosines:  tensor([ 0.3077,  0.7824, -0.1250])\n",
      "16200 ACC:  tensor([0.8915, 0.0418, 0.9511, 0.0431, 0.5817, 0.0318])\n",
      "16800 Err Tr:  tensor([0.0798, 0.1402, 0.0000, 0.4577])\n",
      "16800 Err Te:  tensor([0.0850, 0.0609, 0.2316, 0.0000, 0.5752, 0.1685])\n",
      "16800 Cosines:  tensor([ 0.3002,  0.8080, -0.1078])\n",
      "16800 ACC:  tensor([0.9025, 0.0206, 0.9528, 0.0220, 0.6115, 0.0094])\n",
      "17400 Err Tr:  tensor([0.0791, 0.1417, 0.0000, 0.4563])\n",
      "17400 Err Te:  tensor([0.0827, 0.0600, 0.2342, 0.0000, 0.4726, 0.1936])\n",
      "17400 Cosines:  tensor([ 0.2644,  0.8204, -0.1099])\n",
      "17400 ACC:  tensor([9.0209e-01, 3.2779e-03, 9.5260e-01, 3.6436e-03, 5.9751e-01, 3.7265e-04])\n",
      "18000 Err Tr:  tensor([0.0784, 0.1432, 0.0000, 0.4544])\n",
      "18000 Err Te:  tensor([0.0889, 0.0594, 0.2190, 0.0000, 0.5448, 0.4051])\n",
      "18000 Cosines:  tensor([ 0.3451,  0.7621, -0.1135])\n",
      "18000 ACC:  tensor([0.8810, 0.0000, 0.9457, 0.0000, 0.5898, 0.0000])\n",
      "18600 Err Tr:  tensor([0.0777, 0.1448, 0.0000, 0.4528])\n",
      "18600 Err Te:  tensor([0.0864, 0.0574, 0.2218, 0.0000, 0.5231, 0.2199])\n",
      "18600 Cosines:  tensor([ 0.3258,  0.7894, -0.1221])\n",
      "18600 ACC:  tensor([0.8828, 0.0000, 0.9523, 0.0000, 0.5860, 0.0000])\n",
      "19200 Err Tr:  tensor([0.0771, 0.1461, 0.0000, 0.4511])\n",
      "19200 Err Te:  tensor([0.0818, 0.0590, 0.2156, 0.0000, 0.4651, 0.1851])\n",
      "19200 Cosines:  tensor([ 0.2915,  0.8102, -0.0957])\n",
      "19200 ACC:  tensor([0.8922, 0.0000, 0.9462, 0.0000, 0.5835, 0.0000])\n",
      "19800 Err Tr:  tensor([0.0765, 0.1478, 0.0000, 0.4494])\n",
      "19800 Err Te:  tensor([0.0846, 0.0553, 0.2117, 0.0000, 0.5593, 0.1663])\n",
      "19800 Cosines:  tensor([ 0.3363,  0.7784, -0.0912])\n",
      "19800 ACC:  tensor([0.8801, 0.0000, 0.9476, 0.0000, 0.5654, 0.0000])\n",
      "20400 Err Tr:  tensor([0.0759, 0.1492, 0.0000, 0.4478])\n",
      "20400 Err Te:  tensor([0.0833, 0.0573, 0.2068, 0.0000, 0.5436, 0.2290])\n",
      "20400 Cosines:  tensor([ 0.3092,  0.7993, -0.1053])\n",
      "20400 ACC:  tensor([0.8838, 0.0000, 0.9498, 0.0000, 0.5871, 0.0000])\n",
      "21000 Err Tr:  tensor([0.0753, 0.1508, 0.0000, 0.4461])\n",
      "21000 Err Te:  tensor([0.0852, 0.0555, 0.2067, 0.0000, 0.6798, 0.1596])\n",
      "21000 Cosines:  tensor([ 0.3506,  0.7653, -0.1078])\n",
      "21000 ACC:  tensor([0.8740, 0.0000, 0.9478, 0.0000, 0.5766, 0.0000])\n",
      "21600 Err Tr:  tensor([0.0747, 0.1523, 0.0000, 0.4445])\n",
      "21600 Err Te:  tensor([0.0768, 0.0529, 0.2013, 0.0000, 0.6956, 0.2635])\n",
      "21600 Cosines:  tensor([ 0.3064,  0.8143, -0.1030])\n",
      "21600 ACC:  tensor([0.8981, 0.0000, 0.9503, 0.0000, 0.5784, 0.0000])\n",
      "22200 Err Tr:  tensor([0.0741, 0.1540, 0.0000, 0.4429])\n",
      "22200 Err Te:  tensor([0.0747, 0.0521, 0.1908, 0.0000, 0.5495, 0.3081])\n",
      "22200 Cosines:  tensor([ 0.2670,  0.8154, -0.1029])\n",
      "22200 ACC:  tensor([0.8847, 0.0000, 0.9434, 0.0000, 0.5860, 0.0000])\n",
      "22800 Err Tr:  tensor([0.0734, 0.1558, 0.0000, 0.4414])\n",
      "22800 Err Te:  tensor([0.0765, 0.0506, 0.1870, 0.0000, 0.5452, 0.2891])\n",
      "22800 Cosines:  tensor([ 0.3109,  0.8056, -0.0914])\n",
      "22800 ACC:  tensor([0.8798, 0.0000, 0.9423, 0.0000, 0.5766, 0.0000])\n",
      "23400 Err Tr:  tensor([0.0728, 0.1577, 0.0000, 0.4399])\n",
      "23400 Err Te:  tensor([0.0719, 0.0494, 0.1801, 0.0000, 0.5328, 0.2414])\n",
      "23400 Cosines:  tensor([ 0.2870,  0.8198, -0.1028])\n",
      "23400 ACC:  tensor([8.7615e-01, 4.9443e-04, 9.3689e-01, 5.4184e-04, 5.7633e-01, 1.9642e-04])\n",
      "24000 Err Tr:  tensor([0.0722, 0.1594, 0.0000, 0.4384])\n",
      "24000 Err Te:  tensor([0.0706, 0.0488, 0.1803, 0.0000, 0.4932, 0.1544])\n",
      "24000 Cosines:  tensor([ 0.2898,  0.8095, -0.1077])\n",
      "24000 ACC:  tensor([8.7872e-01, 7.2002e-04, 9.3430e-01, 7.8058e-04, 5.8064e-01, 2.6244e-04])\n",
      "24600 Err Tr:  tensor([0.0716, 0.1610, 0.0000, 0.4370])\n",
      "24600 Err Te:  tensor([0.0675, 0.0481, 0.1770, 0.0000, 0.5323, 0.1774])\n",
      "24600 Cosines:  tensor([ 0.2847,  0.8220, -0.0993])\n",
      "24600 ACC:  tensor([0.8873, 0.0024, 0.9332, 0.0026, 0.5846, 0.0010])\n",
      "25200 Err Tr:  tensor([0.0710, 0.1626, 0.0000, 0.4356])\n",
      "25200 Err Te:  tensor([0.0706, 0.0472, 0.1737, 0.0000, 0.5362, 0.2562])\n",
      "25200 Cosines:  tensor([ 0.3169,  0.8041, -0.0857])\n",
      "25200 ACC:  tensor([0.8789, 0.0071, 0.9365, 0.0077, 0.6010, 0.0037])\n",
      "25800 Err Tr:  tensor([0.0705, 0.1644, 0.0000, 0.4341])\n",
      "25800 Err Te:  tensor([0.0713, 0.0476, 0.1768, 0.0000, 0.5180, 0.2006])\n",
      "25800 Cosines:  tensor([ 0.2812,  0.8139, -0.1031])\n",
      "25800 ACC:  tensor([0.8730, 0.0646, 0.9307, 0.0687, 0.5827, 0.0357])\n",
      "26400 Err Tr:  tensor([0.0699, 0.1661, 0.0000, 0.4326])\n",
      "26400 Err Te:  tensor([0.0691, 0.0464, 0.1762, 0.0000, 0.5681, 0.1938])\n",
      "26400 Cosines:  tensor([ 0.3070,  0.8070, -0.0972])\n",
      "26400 ACC:  tensor([0.8894, 0.1209, 0.9334, 0.1309, 0.6037, 0.0665])\n",
      "27000 Err Tr:  tensor([0.0693, 0.1679, 0.0000, 0.4312])\n",
      "27000 Err Te:  tensor([0.0669, 0.0456, 0.1749, 0.0000, 0.5537, 0.1953])\n",
      "27000 Cosines:  tensor([ 0.2889,  0.8271, -0.0757])\n",
      "27000 ACC:  tensor([0.8865, 0.1308, 0.9314, 0.1420, 0.5900, 0.0590])\n",
      "27600 Err Tr:  tensor([0.0688, 0.1694, 0.0000, 0.4300])\n",
      "27600 Err Te:  tensor([0.0671, 0.0442, 0.1713, 0.0000, 0.5263, 0.1620])\n",
      "27600 Cosines:  tensor([ 0.3184,  0.8011, -0.0875])\n",
      "27600 ACC:  tensor([0.8765, 0.1496, 0.9298, 0.1603, 0.5945, 0.0757])\n",
      "28200 Err Tr:  tensor([0.0682, 0.1709, 0.0000, 0.4287])\n",
      "28200 Err Te:  tensor([0.0621, 0.0429, 0.1695, 0.0000, 0.5474, 0.2422])\n",
      "28200 Cosines:  tensor([ 0.2977,  0.8181, -0.0947])\n",
      "28200 ACC:  tensor([0.8866, 0.1497, 0.9294, 0.1600, 0.6054, 0.0831])\n",
      "28800 Err Tr:  tensor([0.0676, 0.1726, 0.0000, 0.4272])\n",
      "28800 Err Te:  tensor([0.0618, 0.0420, 0.1645, 0.0000, 0.6009, 0.2003])\n",
      "28800 Cosines:  tensor([ 0.3151,  0.8063, -0.0853])\n",
      "28800 ACC:  tensor([0.8854, 0.1741, 0.9293, 0.1878, 0.6146, 0.1024])\n",
      "29400 Err Tr:  tensor([0.0671, 0.1739, 0.0000, 0.4258])\n",
      "29400 Err Te:  tensor([0.0634, 0.0410, 0.1669, 0.0000, 0.5197, 0.2232])\n",
      "29400 Cosines:  tensor([ 0.3264,  0.8046, -0.0942])\n",
      "29400 ACC:  tensor([0.8798, 0.1707, 0.9277, 0.1837, 0.5866, 0.0882])\n",
      "30000 Err Tr:  tensor([0.0665, 0.1754, 0.0000, 0.4245])\n",
      "30000 Err Te:  tensor([0.0649, 0.0397, 0.1661, 0.0000, 0.5902, 0.2124])\n",
      "30000 Cosines:  tensor([ 0.3281,  0.7866, -0.0898])\n",
      "30000 ACC:  tensor([0.8717, 0.1600, 0.9286, 0.1769, 0.5993, 0.0848])\n",
      "30600 Err Tr:  tensor([0.0659, 0.1770, 0.0000, 0.4232])\n",
      "30600 Err Te:  tensor([0.0645, 0.0417, 0.1616, 0.0000, 0.5146, 0.3168])\n",
      "30600 Cosines:  tensor([ 0.3122,  0.8096, -0.0741])\n",
      "30600 ACC:  tensor([0.8723, 0.1175, 0.9275, 0.1306, 0.6215, 0.0646])\n",
      "31200 Err Tr:  tensor([0.0654, 0.1785, 0.0000, 0.4219])\n",
      "31200 Err Te:  tensor([0.0589, 0.0394, 0.1634, 0.0000, 0.5179, 0.3899])\n",
      "31200 Cosines:  tensor([ 0.3134,  0.8297, -0.0696])\n",
      "31200 ACC:  tensor([0.8830, 0.1265, 0.9278, 0.1400, 0.6005, 0.0724])\n",
      "31800 Err Tr:  tensor([0.0648, 0.1802, 0.0000, 0.4206])\n",
      "31800 Err Te:  tensor([0.0566, 0.0379, 0.1612, 0.0000, 0.6384, 0.3271])\n",
      "31800 Cosines:  tensor([ 0.3102,  0.8289, -0.0736])\n",
      "31800 ACC:  tensor([0.8925, 0.1022, 0.9313, 0.1153, 0.6185, 0.0526])\n",
      "32400 Err Tr:  tensor([0.0643, 0.1817, 0.0000, 0.4194])\n",
      "32400 Err Te:  tensor([0.0604, 0.0374, 0.1569, 0.0000, 0.5250, 0.2717])\n",
      "32400 Cosines:  tensor([ 0.3261,  0.7932, -0.0814])\n",
      "32400 ACC:  tensor([0.8749, 0.0994, 0.9276, 0.1099, 0.6069, 0.0534])\n",
      "33000 Err Tr:  tensor([0.0638, 0.1833, 0.0000, 0.4181])\n",
      "33000 Err Te:  tensor([0.0605, 0.0379, 0.1590, 0.0000, 0.6599, 0.1872])\n",
      "33000 Cosines:  tensor([ 0.3321,  0.7983, -0.0782])\n",
      "33000 ACC:  tensor([0.8665, 0.0927, 0.9252, 0.1060, 0.6079, 0.0532])\n",
      "33600 Err Tr:  tensor([0.0633, 0.1849, 0.0000, 0.4168])\n",
      "33600 Err Te:  tensor([0.0606, 0.0372, 0.1543, 0.0000, 0.5300, 0.3188])\n",
      "33600 Cosines:  tensor([ 0.3374,  0.7928, -0.0732])\n",
      "33600 ACC:  tensor([0.8726, 0.0811, 0.9263, 0.0935, 0.6188, 0.0423])\n",
      "34200 Err Tr:  tensor([0.0628, 0.1865, 0.0000, 0.4155])\n",
      "34200 Err Te:  tensor([0.0599, 0.0369, 0.1566, 0.0000, 0.5685, 0.2545])\n",
      "34200 Cosines:  tensor([ 0.3354,  0.7950, -0.0879])\n",
      "34200 ACC:  tensor([0.8870, 0.0670, 0.9292, 0.0769, 0.6315, 0.0341])\n",
      "34800 Err Tr:  tensor([0.0623, 0.1880, 0.0000, 0.4143])\n",
      "34800 Err Te:  tensor([0.0583, 0.0397, 0.1564, 0.0000, 0.5596, 0.2525])\n",
      "34800 Cosines:  tensor([ 0.3112,  0.8242, -0.0857])\n",
      "34800 ACC:  tensor([0.8763, 0.0507, 0.9223, 0.0554, 0.6059, 0.0230])\n",
      "35400 Err Tr:  tensor([0.0619, 0.1896, 0.0000, 0.4132])\n",
      "35400 Err Te:  tensor([0.0586, 0.0376, 0.1559, 0.0000, 0.5529, 0.1956])\n",
      "35400 Cosines:  tensor([ 0.3389,  0.8049, -0.0727])\n",
      "35400 ACC:  tensor([0.8744, 0.0314, 0.9232, 0.0335, 0.6144, 0.0127])\n",
      "36000 Err Tr:  tensor([0.0614, 0.1910, 0.0000, 0.4120])\n",
      "36000 Err Te:  tensor([0.0578, 0.0368, 0.1539, 0.0000, 0.5990, 0.2587])\n",
      "36000 Cosines:  tensor([ 0.3149,  0.8036, -0.0871])\n",
      "36000 ACC:  tensor([0.8726, 0.0468, 0.9221, 0.0517, 0.6106, 0.0246])\n",
      "36600 Err Tr:  tensor([0.0610, 0.1924, 0.0000, 0.4109])\n",
      "36600 Err Te:  tensor([0.0555, 0.0357, 0.1521, 0.0000, 0.6516, 0.2949])\n",
      "36600 Cosines:  tensor([ 0.3078,  0.8044, -0.0778])\n",
      "36600 ACC:  tensor([0.8722, 0.0294, 0.9204, 0.0335, 0.6154, 0.0135])\n",
      "37200 Err Tr:  tensor([0.0605, 0.1938, 0.0000, 0.4099])\n",
      "37200 Err Te:  tensor([0.0631, 0.0368, 0.1535, 0.0000, 0.6039, 0.3739])\n",
      "37200 Cosines:  tensor([ 0.3710,  0.7648, -0.0748])\n",
      "37200 ACC:  tensor([0.8623, 0.0310, 0.9220, 0.0372, 0.6174, 0.0149])\n",
      "37800 Err Tr:  tensor([0.0601, 0.1953, 0.0000, 0.4087])\n",
      "37800 Err Te:  tensor([0.0563, 0.0361, 0.1497, 0.0000, 0.6065, 0.2715])\n",
      "37800 Cosines:  tensor([ 0.3215,  0.8128, -0.0671])\n",
      "37800 ACC:  tensor([0.8684, 0.0204, 0.9175, 0.0235, 0.6145, 0.0089])\n",
      "38400 Err Tr:  tensor([0.0597, 0.1970, 0.0000, 0.4076])\n",
      "38400 Err Te:  tensor([0.0581, 0.0361, 0.1472, 0.0000, 0.5662, 0.4337])\n",
      "38400 Cosines:  tensor([ 0.3472,  0.7916, -0.0670])\n",
      "38400 ACC:  tensor([0.8629, 0.0222, 0.9176, 0.0250, 0.6363, 0.0127])\n",
      "39000 Err Tr:  tensor([0.0593, 0.1985, 0.0000, 0.4064])\n",
      "39000 Err Te:  tensor([0.0539, 0.0367, 0.1489, 0.0000, 0.5595, 0.3368])\n",
      "39000 Cosines:  tensor([ 0.2920,  0.8287, -0.0798])\n",
      "39000 ACC:  tensor([0.8733, 0.0105, 0.9159, 0.0122, 0.6028, 0.0044])\n",
      "39600 Err Tr:  tensor([0.0589, 0.1999, 0.0000, 0.4052])\n",
      "39600 Err Te:  tensor([0.0555, 0.0353, 0.1458, 0.0000, 0.6666, 0.3092])\n",
      "39600 Cosines:  tensor([ 0.3182,  0.7996, -0.0745])\n",
      "39600 ACC:  tensor([0.8744, 0.0152, 0.9230, 0.0175, 0.6224, 0.0059])\n",
      "40200 Err Tr:  tensor([0.0585, 0.2014, 0.0000, 0.4041])\n",
      "40200 Err Te:  tensor([0.0537, 0.0355, 0.1485, 0.0000, 0.5148, 0.1856])\n",
      "40200 Cosines:  tensor([ 0.2896,  0.8358, -0.0773])\n",
      "40200 ACC:  tensor([0.8692, 0.0064, 0.9184, 0.0078, 0.6037, 0.0021])\n",
      "40800 Err Tr:  tensor([0.0582, 0.2028, 0.0000, 0.4031])\n",
      "40800 Err Te:  tensor([0.0520, 0.0355, 0.1423, 0.0000, 0.5650, 0.2636])\n",
      "40800 Cosines:  tensor([ 0.2981,  0.8177, -0.0767])\n",
      "40800 ACC:  tensor([8.7313e-01, 2.5746e-03, 9.1404e-01, 3.2939e-03, 6.1019e-01, 5.1089e-04])\n",
      "41400 Err Tr:  tensor([0.0578, 0.2044, 0.0000, 0.4020])\n",
      "41400 Err Te:  tensor([0.0545, 0.0356, 0.1418, 0.0000, 0.5723, 0.2627])\n",
      "41400 Cosines:  tensor([ 0.3186,  0.8077, -0.0735])\n",
      "41400 ACC:  tensor([8.6586e-01, 3.0189e-03, 9.1210e-01, 3.8892e-03, 6.1638e-01, 6.9353e-04])\n",
      "42000 Err Tr:  tensor([0.0575, 0.2058, 0.0000, 0.4010])\n",
      "42000 Err Te:  tensor([0.0534, 0.0356, 0.1433, 0.0000, 0.6856, 0.2521])\n",
      "42000 Cosines:  tensor([ 0.3109,  0.8186, -0.0750])\n",
      "42000 ACC:  tensor([8.7512e-01, 1.9993e-03, 9.1393e-01, 2.4307e-03, 6.3761e-01, 6.5046e-04])\n",
      "42600 Err Tr:  tensor([0.0571, 0.2073, 0.0000, 0.4000])\n",
      "42600 Err Te:  tensor([0.0532, 0.0355, 0.1423, 0.0000, 0.5709, 0.3192])\n",
      "42600 Cosines:  tensor([ 0.2978,  0.8293, -0.0633])\n",
      "42600 ACC:  tensor([8.6468e-01, 4.4734e-04, 9.0792e-01, 5.9865e-04, 6.1163e-01, 8.5522e-05])\n",
      "43200 Err Tr:  tensor([0.0568, 0.2088, 0.0000, 0.3990])\n",
      "43200 Err Te:  tensor([0.0502, 0.0355, 0.1429, 0.0000, 0.5865, 0.3114])\n",
      "43200 Cosines:  tensor([ 0.2698,  0.8450, -0.0753])\n",
      "43200 ACC:  tensor([8.7844e-01, 1.3745e-04, 9.0886e-01, 1.5055e-04, 6.4541e-01, 6.5454e-06])\n",
      "43800 Err Tr:  tensor([0.0565, 0.2103, 0.0000, 0.3980])\n",
      "43800 Err Te:  tensor([0.0532, 0.0353, 0.1431, 0.0000, 0.7034, 0.4334])\n",
      "43800 Cosines:  tensor([ 0.2896,  0.8238, -0.0774])\n",
      "43800 ACC:  tensor([8.6638e-01, 2.5970e-04, 9.1074e-01, 3.8271e-04, 6.0423e-01, 4.7839e-05])\n",
      "44400 Err Tr:  tensor([0.0561, 0.2119, 0.0000, 0.3970])\n",
      "44400 Err Te:  tensor([0.0508, 0.0351, 0.1394, 0.0000, 0.5829, 0.2472])\n",
      "44400 Cosines:  tensor([ 0.2904,  0.8361, -0.0682])\n",
      "44400 ACC:  tensor([8.6751e-01, 4.1590e-04, 9.0844e-01, 5.2323e-04, 6.0986e-01, 1.6770e-04])\n",
      "45000 Err Tr:  tensor([0.0558, 0.2133, 0.0000, 0.3959])\n",
      "45000 Err Te:  tensor([0.0525, 0.0359, 0.1395, 0.0000, 0.5689, 0.3480])\n",
      "45000 Cosines:  tensor([ 0.2905,  0.8325, -0.0651])\n",
      "45000 ACC:  tensor([8.6447e-01, 4.2120e-05, 9.0621e-01, 5.6160e-05, 6.2455e-01, 7.0200e-06])\n",
      "45600 Err Tr:  tensor([0.0555, 0.2148, 0.0000, 0.3949])\n",
      "45600 Err Te:  tensor([0.0545, 0.0350, 0.1368, 0.0000, 0.6294, 0.2835])\n",
      "45600 Cosines:  tensor([ 0.3185,  0.8115, -0.0651])\n",
      "45600 ACC:  tensor([8.5896e-01, 9.7799e-04, 9.0696e-01, 1.0669e-03, 6.1584e-01, 5.0609e-04])\n",
      "46200 Err Tr:  tensor([0.0552, 0.2162, 0.0000, 0.3940])\n",
      "46200 Err Te:  tensor([0.0496, 0.0351, 0.1374, 0.0000, 0.5880, 0.3150])\n",
      "46200 Cosines:  tensor([ 0.2745,  0.8496, -0.0691])\n",
      "46200 ACC:  tensor([8.7504e-01, 2.7571e-04, 9.0708e-01, 4.1692e-04, 5.9805e-01, 1.0759e-04])\n",
      "46800 Err Tr:  tensor([0.0549, 0.2176, 0.0000, 0.3930])\n",
      "46800 Err Te:  tensor([0.0521, 0.0350, 0.1388, 0.0000, 0.6326, 0.4908])\n",
      "46800 Cosines:  tensor([ 0.3028,  0.8275, -0.0742])\n",
      "46800 ACC:  tensor([8.7258e-01, 4.2546e-05, 9.0831e-01, 7.0910e-05, 6.6356e-01, 1.4182e-05])\n",
      "47400 Err Tr:  tensor([0.0546, 0.2190, 0.0000, 0.3920])\n",
      "47400 Err Te:  tensor([0.0507, 0.0345, 0.1319, 0.0000, 0.5871, 0.3061])\n",
      "47400 Cosines:  tensor([ 0.3101,  0.8232, -0.0731])\n",
      "47400 ACC:  tensor([8.6102e-01, 2.9043e-04, 9.0376e-01, 3.4323e-04, 6.1029e-01, 7.9208e-05])\n",
      "48000 Err Tr:  tensor([0.0543, 0.2205, 0.0000, 0.3911])\n",
      "48000 Err Te:  tensor([0.0495, 0.0343, 0.1324, 0.0000, 0.6487, 0.3264])\n",
      "48000 Cosines:  tensor([ 0.2856,  0.8371, -0.0674])\n",
      "48000 ACC:  tensor([8.6148e-01, 1.5111e-04, 8.9771e-01, 2.1024e-04, 6.0016e-01, 2.6281e-05])\n",
      "48600 Err Tr:  tensor([0.0540, 0.2219, 0.0000, 0.3902])\n",
      "48600 Err Te:  tensor([0.0502, 0.0330, 0.1316, 0.0000, 0.6912, 0.2595])\n",
      "48600 Cosines:  tensor([ 0.3028,  0.8249, -0.0758])\n",
      "48600 ACC:  tensor([8.5479e-01, 1.9813e-05, 8.9695e-01, 1.9813e-05, 5.8410e-01, 1.3208e-05])\n",
      "49200 Err Tr:  tensor([0.0538, 0.2234, 0.0000, 0.3893])\n",
      "49200 Err Te:  tensor([0.0536, 0.0344, 0.1322, 0.0000, 0.6025, 0.3141])\n",
      "49200 Cosines:  tensor([ 0.3320,  0.7952, -0.0754])\n",
      "49200 ACC:  tensor([8.5017e-01, 4.8060e-05, 8.9410e-01, 4.8060e-05, 6.1538e-01, 2.0597e-05])\n",
      "49800 Err Tr:  tensor([0.0535, 0.2247, 0.0000, 0.3883])\n",
      "49800 Err Te:  tensor([0.0489, 0.0343, 0.1309, 0.0000, 0.5856, 0.3459])\n",
      "49800 Cosines:  tensor([ 0.2865,  0.8402, -0.0704])\n",
      "49800 ACC:  tensor([8.5677e-01, 4.6984e-05, 8.9459e-01, 6.0408e-05, 5.9911e-01, 2.0136e-05])\n",
      "50400 Err Tr:  tensor([0.0532, 0.2262, 0.0000, 0.3874])\n",
      "50400 Err Te:  tensor([0.0509, 0.0344, 0.1274, 0.0000, 0.6311, 0.2549])\n",
      "50400 Cosines:  tensor([ 0.3220,  0.8247, -0.0545])\n",
      "50400 ACC:  tensor([8.4358e-01, 6.0738e-05, 8.9124e-01, 8.0984e-05, 5.9451e-01, 4.0492e-05])\n",
      "51000 Err Tr:  tensor([0.0530, 0.2276, 0.0000, 0.3865])\n",
      "51000 Err Te:  tensor([0.0492, 0.0334, 0.1256, 0.0000, 0.6020, 0.2901])\n",
      "51000 Cosines:  tensor([ 0.3345,  0.8218, -0.0541])\n",
      "51000 ACC:  tensor([8.4130e-01, 9.1293e-05, 8.8965e-01, 1.6954e-04, 6.0800e-01, 5.2168e-05])\n",
      "51600 Err Tr:  tensor([0.0527, 0.2290, 0.0000, 0.3856])\n",
      "51600 Err Te:  tensor([0.0522, 0.0338, 0.1275, 0.0000, 0.6692, 0.4298])\n",
      "51600 Cosines:  tensor([ 0.3526,  0.8032, -0.0525])\n",
      "51600 ACC:  tensor([8.4483e-01, 5.9016e-05, 8.9089e-01, 7.2130e-05, 5.9632e-01, 2.6229e-05])\n",
      "52200 Err Tr:  tensor([0.0525, 0.2304, 0.0000, 0.3847])\n",
      "52200 Err Te:  tensor([0.0494, 0.0335, 0.1268, 0.0000, 0.5931, 0.3480])\n",
      "52200 Cosines:  tensor([ 0.3118,  0.8297, -0.0624])\n",
      "52200 ACC:  tensor([8.4092e-01, 1.6542e-04, 8.9247e-01, 1.7980e-04, 6.0064e-01, 8.6306e-05])\n",
      "52800 Err Tr:  tensor([0.0522, 0.2319, 0.0000, 0.3838])\n",
      "52800 Err Te:  tensor([0.0497, 0.0333, 0.1238, 0.0000, 0.6010, 0.4303])\n",
      "52800 Cosines:  tensor([ 0.3304,  0.8158, -0.0611])\n",
      "52800 ACC:  tensor([8.3424e-01, 8.1817e-05, 8.8676e-01, 1.1591e-04, 5.8977e-01, 2.7272e-05])\n",
      "53400 Err Tr:  tensor([0.0520, 0.2332, 0.0000, 0.3829])\n",
      "53400 Err Te:  tensor([0.0510, 0.0342, 0.1246, 0.0000, 0.5604, 0.2847])\n",
      "53400 Cosines:  tensor([ 0.3248,  0.8212, -0.0516])\n",
      "53400 ACC:  tensor([8.3297e-01, 2.0845e-05, 8.8406e-01, 2.0845e-05, 5.8956e-01, 6.9482e-06])\n",
      "54000 Err Tr:  tensor([0.0517, 0.2346, 0.0000, 0.3821])\n",
      "54000 Err Te:  tensor([0.0458, 0.0327, 0.1212, 0.0000, 0.6093, 0.3130])\n",
      "54000 Cosines:  tensor([ 0.2974,  0.8441, -0.0542])\n",
      "54000 ACC:  tensor([8.5099e-01, 6.6743e-05, 8.8855e-01, 6.6743e-05, 5.9828e-01, 4.6720e-05])\n",
      "54600 Err Tr:  tensor([0.0515, 0.2359, 0.0000, 0.3812])\n",
      "54600 Err Te:  tensor([0.0474, 0.0327, 0.1181, 0.0000, 0.6268, 0.3524])\n",
      "54600 Cosines:  tensor([ 0.3014,  0.8195, -0.0644])\n",
      "54600 ACC:  tensor([8.3091e-01, 1.1776e-04, 8.8220e-01, 1.4547e-04, 5.7294e-01, 4.1564e-05])\n",
      "55200 Err Tr:  tensor([0.0513, 0.2372, 0.0000, 0.3804])\n",
      "55200 Err Te:  tensor([0.0493, 0.0329, 0.1217, 0.0000, 0.5414, 0.4624])\n",
      "55200 Cosines:  tensor([ 0.3178,  0.8155, -0.0584])\n",
      "55200 ACC:  tensor([8.2782e-01, 3.1072e-04, 8.7936e-01, 3.3143e-04, 5.8471e-01, 1.5191e-04])\n",
      "55800 Err Tr:  tensor([0.0510, 0.2387, 0.0000, 0.3795])\n",
      "55800 Err Te:  tensor([0.0473, 0.0325, 0.1171, 0.0000, 0.5961, 0.3287])\n",
      "55800 Cosines:  tensor([ 0.3206,  0.8311, -0.0560])\n",
      "55800 ACC:  tensor([8.3506e-01, 1.8171e-04, 8.8230e-01, 1.9568e-04, 5.8712e-01, 1.1182e-04])\n",
      "56400 Err Tr:  tensor([0.0508, 0.2398, 0.0000, 0.3788])\n",
      "56400 Err Te:  tensor([0.0481, 0.0338, 0.1200, 0.0000, 0.5907, 0.4124])\n",
      "56400 Cosines:  tensor([ 0.3042,  0.8232, -0.0743])\n",
      "56400 ACC:  tensor([8.2620e-01, 8.7455e-05, 8.7007e-01, 8.7455e-05, 5.7607e-01, 2.6909e-05])\n",
      "57000 Err Tr:  tensor([0.0506, 0.2411, 0.0000, 0.3780])\n",
      "57000 Err Te:  tensor([0.0461, 0.0322, 0.1167, 0.0000, 0.5034, 0.3627])\n",
      "57000 Cosines:  tensor([ 0.2883,  0.8316, -0.0676])\n",
      "57000 ACC:  tensor([8.3113e-01, 9.1313e-05, 8.7566e-01, 1.1088e-04, 5.8381e-01, 6.5224e-05])\n",
      "57600 Err Tr:  tensor([0.0504, 0.2423, 0.0000, 0.3772])\n",
      "57600 Err Te:  tensor([0.0454, 0.0332, 0.1137, 0.0000, 0.5885, 0.3669])\n",
      "57600 Cosines:  tensor([ 0.2777,  0.8607, -0.0501])\n",
      "57600 ACC:  tensor([8.2908e-01, 1.9512e-04, 8.6748e-01, 2.1463e-04, 5.6962e-01, 1.1707e-04])\n",
      "58200 Err Tr:  tensor([0.0502, 0.2436, 0.0000, 0.3764])\n",
      "58200 Err Te:  tensor([0.0432, 0.0314, 0.1123, 0.0000, 0.6074, 0.3660])\n",
      "58200 Cosines:  tensor([ 0.2971,  0.8542, -0.0519])\n",
      "58200 ACC:  tensor([8.3445e-01, 2.2511e-04, 8.6739e-01, 2.3918e-04, 6.0107e-01, 1.4069e-04])\n",
      "58800 Err Tr:  tensor([0.0500, 0.2449, 0.0000, 0.3756])\n",
      "58800 Err Te:  tensor([0.0470, 0.0334, 0.1143, 0.0000, 0.5801, 0.3798])\n",
      "58800 Cosines:  tensor([ 0.2777,  0.8419, -0.0574])\n",
      "58800 ACC:  tensor([8.2256e-01, 7.3885e-05, 8.6954e-01, 8.0602e-05, 5.8934e-01, 5.3735e-05])\n",
      "59400 Err Tr:  tensor([0.0498, 0.2463, 0.0000, 0.3749])\n",
      "59400 Err Te:  tensor([0.0461, 0.0327, 0.1137, 0.0000, 0.7496, 0.3825])\n",
      "59400 Cosines:  tensor([ 0.3059,  0.8308, -0.0542])\n",
      "59400 ACC:  tensor([8.1716e-01, 2.3219e-04, 8.6937e-01, 2.9366e-04, 6.0443e-01, 1.4341e-04])\n"
     ]
    }
   ],
   "source": [
    "SETTINGS=[0.5]\n",
    "eta_consistency=0\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "SAVE=True\n",
    "PLOT=False\n",
    "PRO=1\n",
    "\n",
    "LOAD=False\n",
    "\n",
    "if LOAD:\n",
    "\n",
    "    self_model=torch.load('Model_simple_after_pred_cutFalse.pt')\n",
    "    self_model.Override_Predictive(F_Ns, dt, lr=0.001)\n",
    "    \n",
    "\n",
    "N_log=100\n",
    "\n",
    "N_train1=10000\n",
    "N_checks1=np.unique(np.int32(np.exp(np.linspace(0,np.log(N_train1),N_log))))\n",
    "\n",
    "N_train2=50000\n",
    "N_checks2=np.unique(np.int32(np.exp(np.linspace(0,np.log(N_train2),N_log))))+N_train1\n",
    "N_checks=np.concatenate([N_checks1, N_checks2],0)\n",
    "N_train=N_train1+N_train2\n",
    "\n",
    "N_checks=np.arange(0,101)*600#+10000\n",
    "\n",
    "N_check=N_checks.shape[0]\n",
    "\n",
    "ind_help=0\n",
    "\n",
    "MSE_Train_corr=torch.zeros([4,N_train])\n",
    "MSE_Tr_corr=torch.zeros([4,N_check])\n",
    "MSE_Te_corr=torch.zeros([6,N_check])\n",
    "ACC_Te=torch.zeros([6,N_check])\n",
    "Cosines=torch.zeros([3,N_check])\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "ind_help=0\n",
    "\n",
    "T_hor=3\n",
    "T_hor_val=5\n",
    "\n",
    "for k in range(0,N_train1+N_train2):\n",
    "    \n",
    "    x_b, y_b=Data.Batch(batch_size)\n",
    "    X_b, Y_b, A_b, x0s, t0s=Data.Batch_ODE(batch_size, T_horizon=T_hor)\n",
    "    \n",
    "    recon_loss1, joint_loss1, consistency_loss1, pro_rec1, z_self, z_other, \\\n",
    "        img, img_self, img_other, mask_self, mask_other=self_model.Correlation_forward(x_b, y_b, X_b, Y_b, A_b, x0s, t0s, n=k, PRO=PRO, eta_consistency=eta_consistency)\n",
    "    \n",
    "    MSE_Train_corr[0,k]=recon_loss1.detach()\n",
    "    MSE_Train_corr[1,k]=pro_rec1.detach()\n",
    "    MSE_Train_corr[2,k]=joint_loss1.detach()\n",
    "    MSE_Train_corr[3,k]=consistency_loss1.detach()\n",
    "\n",
    "    if np.any(k==N_checks):\n",
    "        \n",
    "        if k>0:\n",
    "            \n",
    "            mse_mean=torch.mean(MSE_Train_corr[:,k-N_checks[ind_help-1]:k],1)\n",
    "        \n",
    "            MSE_Tr_corr[:,ind_help]=mse_mean\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            MSE_Tr_corr[:,ind_help]=MSE_Train_corr[:,k]\n",
    "        \n",
    "        x_b, y_b, lab=Data.Evaluate(batch_size*10)\n",
    "        X_te, Y_te, A_te, x0s, t0s, lab_=Data.Evaluate_ODE(batch_size, T_horizon_val=T_hor_val)\n",
    "\n",
    "        recon_loss_mixed, recon_loss_visual, recon_loss_pro, joint_loss, recon_pro_loss, consistency_loss, \\\n",
    "        acc_self_mixed, acc_other_mixed, acc_self_pro, acc_other_pro, acc_self_visual, acc_other_visual, \\\n",
    "        img_mixed, img_self_mixed, img_other_mixed, mask_self_mixed, mask_other_mixed, \\\n",
    "        img_visual, img_self_visual, img_other_visual, mask_self_visual, mask_other_visual, \\\n",
    "        img_pro, img_self_pro, img_other_pro, mask_self_pro, mask_other_pro, \\\n",
    "        cosine_mixed, cosine_visual, cosine_pro = self_model.Correlation_Eval(x_b, y_b, X_te, Y_te, A_te, x0s, t0s, k, lab, TRAIN=False, PRO=PRO)\n",
    "        \n",
    "        MSE_Te_corr[0,ind_help]=recon_loss_mixed.detach()\n",
    "        MSE_Te_corr[1,ind_help]=recon_loss_visual.detach()\n",
    "        MSE_Te_corr[2,ind_help]=recon_loss_pro.detach()\n",
    "        MSE_Te_corr[3,ind_help]=joint_loss.detach()\n",
    "        MSE_Te_corr[4,ind_help]=recon_pro_loss.detach()\n",
    "        MSE_Te_corr[5,ind_help]=consistency_loss.detach()\n",
    "\n",
    "        ACC_Te[0,ind_help]=acc_self_mixed\n",
    "        ACC_Te[1,ind_help]=acc_other_mixed\n",
    "        ACC_Te[2,ind_help]=acc_self_visual\n",
    "        ACC_Te[3,ind_help]=acc_other_visual\n",
    "        ACC_Te[4,ind_help]=acc_self_pro\n",
    "        ACC_Te[5,ind_help]=acc_other_pro\n",
    "        \n",
    "        Cosines[0,ind_help]=cosine_mixed\n",
    "        Cosines[1,ind_help]=cosine_visual\n",
    "        Cosines[2,ind_help]=cosine_pro\n",
    "        \n",
    "        \n",
    "        print(k,'Err Tr: ', MSE_Tr_corr[:,ind_help])\n",
    "        print(k,'Err Te: ', MSE_Te_corr[:,ind_help])\n",
    "        print(k,'Cosines: ', Cosines[:,ind_help])\n",
    "        print(k,'ACC: ', ACC_Te[:,ind_help])\n",
    "        \n",
    "        ind_help+=1\n",
    "\n",
    "        if SAVE:\n",
    "\n",
    "            #title_model='Model_simple_after_corr_cutFalse_loc2.pt'\n",
    "            title_model='Model_simple_after_corr_cutFalse_Vision_Only_0_Lpy.pt'\n",
    "            torch.save(self_model, title_model)\n",
    "\n",
    "            title_results='Results_simple_after_corr_cutFalse_Vision_Only_0_Lpy'\n",
    "            np.savez(title_results, MSE_Train_corr=MSE_Train_corr, MSE_Tr_corr=MSE_Tr_corr, MSE_Te_corr=MSE_Te_corr, N_checks=N_checks, Cosines=Cosines, ACC_Te=ACC_Te)\n",
    "        \n",
    "        if PLOT:\n",
    "\n",
    "            for p in range(2):\n",
    "            \n",
    "                fig, ax = plt.subplots(3, 6, figsize=(10, 5))\n",
    "    \n",
    "                ax[0,0].imshow(x_b[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[0,1].imshow(img_mixed[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[0,2].imshow(img_self_mixed[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[0,3].imshow(img_other_mixed[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[0,4].imshow(mask_self_mixed[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[0,5].imshow(mask_other_mixed[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "\n",
    "    \n",
    "                ax[1,0].imshow(x_b[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[1,1].imshow(img_visual[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[1,2].imshow(img_self_visual[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[1,3].imshow(img_other_visual[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[1,4].imshow(mask_self_visual[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[1,5].imshow(mask_other_visual[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "\n",
    "\n",
    "                ax[2,0].imshow(x_b[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[2,1].imshow(img_pro[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[2,2].imshow(img_self_pro[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[2,3].imshow(img_other_pro[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[2,4].imshow(mask_self_pro[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "                ax[2,5].imshow(mask_other_pro[p,0:3].detach().permute(1,2,0).to('cpu'))\n",
    "    \n",
    "                plt.show()\n",
    "\n",
    "\n",
    "            T_hor_val=50\n",
    "            X_te, Y_te, A_te, x0s, t0s, lab_=Data.Evaluate_ODE(batch_size, T_horizon_val=T_hor_val)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "               _, _, _, _, Z_te, _=self_model.Predictive_forward(X_te,Y_te,A_te,t0s,TRAIN=False)\n",
    "\n",
    "            \n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "            for n in range(10):\n",
    "\n",
    "                plt.plot(Z_te[0,n,:].detach().to('cpu'))\n",
    "\n",
    "            del X_te, Y_te, A_te, x0s, t0s, Z_te\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5afbeacf-4f4a-46e3-8a62-0d70f92c0830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err Tr:  tensor([nan, nan])\n",
      "Err Te:  tensor(2.4954) tensor(0.6030)\n",
      "Err Tr:  tensor([2.7454, 0.8961])\n",
      "Err Te:  tensor(3.4772) tensor(0.6785)\n",
      "Err Tr:  tensor([2.8761, 0.8143])\n",
      "Err Te:  tensor(3.1973) tensor(0.7340)\n",
      "Err Tr:  tensor([2.8354, 0.7915])\n",
      "Err Te:  tensor(2.4621) tensor(0.6370)\n",
      "Err Tr:  tensor([2.8032, 0.7795])\n",
      "Err Te:  tensor(3.4978) tensor(0.7127)\n",
      "Err Tr:  tensor([2.7628, 0.8257])\n",
      "Err Te:  tensor(3.1143) tensor(0.5717)\n",
      "Err Tr:  tensor([2.7065, 0.8022])\n",
      "Err Te:  tensor(2.8894) tensor(0.5502)\n",
      "Err Tr:  tensor([2.6877, 0.7766])\n",
      "Err Te:  tensor(2.7933) tensor(0.5943)\n",
      "Err Tr:  tensor([2.6180, 0.7644])\n",
      "Err Te:  tensor(2.4236) tensor(0.6028)\n",
      "Err Tr:  tensor([2.4870, 0.7357])\n",
      "Err Te:  tensor(2.0961) tensor(0.5956)\n",
      "Err Tr:  tensor([2.5248, 0.7379])\n",
      "Err Te:  tensor(1.7315) tensor(0.6465)\n",
      "Err Tr:  tensor([2.5359, 0.7291])\n",
      "Err Te:  tensor(2.8652) tensor(0.6374)\n",
      "Err Tr:  tensor([2.5114, 0.7101])\n",
      "Err Te:  tensor(2.5020) tensor(0.6489)\n",
      "Err Tr:  tensor([2.4640, 0.6989])\n",
      "Err Te:  tensor(2.0380) tensor(0.5865)\n",
      "Err Tr:  tensor([2.4804, 0.6879])\n",
      "Err Te:  tensor(2.6142) tensor(0.6119)\n",
      "Err Tr:  tensor([2.4506, 0.6819])\n",
      "Err Te:  tensor(2.3895) tensor(0.5395)\n",
      "Err Tr:  tensor([2.3804, 0.6724])\n",
      "Err Te:  tensor(2.4160) tensor(0.6111)\n",
      "Err Tr:  tensor([2.3113, 0.6629])\n",
      "Err Te:  tensor(2.5332) tensor(0.5943)\n",
      "Err Tr:  tensor([2.2824, 0.6546])\n",
      "Err Te:  tensor(2.4902) tensor(0.6301)\n",
      "Err Tr:  tensor([2.2054, 0.6390])\n",
      "Err Te:  tensor(1.9346) tensor(0.5481)\n",
      "Err Tr:  tensor([2.1930, 0.6387])\n",
      "Err Te:  tensor(1.9699) tensor(0.5712)\n",
      "Err Tr:  tensor([2.0895, 0.6198])\n",
      "Err Te:  tensor(2.2694) tensor(0.6096)\n",
      "Err Tr:  tensor([2.0736, 0.6168])\n",
      "Err Te:  tensor(2.2068) tensor(0.6216)\n",
      "Err Tr:  tensor([1.9975, 0.5970])\n",
      "Err Te:  tensor(1.5689) tensor(0.5232)\n",
      "Err Tr:  tensor([1.9705, 0.5970])\n",
      "Err Te:  tensor(2.0990) tensor(0.6130)\n",
      "Err Tr:  tensor([1.9383, 0.5931])\n",
      "Err Te:  tensor(2.0125) tensor(0.5913)\n",
      "Err Tr:  tensor([1.8927, 0.5848])\n",
      "Err Te:  tensor(1.6896) tensor(0.5911)\n",
      "Err Tr:  tensor([1.8739, 0.5803])\n",
      "Err Te:  tensor(1.7307) tensor(0.5984)\n",
      "Err Tr:  tensor([1.8363, 0.5778])\n",
      "Err Te:  tensor(1.7617) tensor(0.5368)\n",
      "Err Tr:  tensor([1.7896, 0.5720])\n",
      "Err Te:  tensor(2.1032) tensor(0.5844)\n",
      "Err Tr:  tensor([1.7674, 0.5674])\n",
      "Err Te:  tensor(1.3637) tensor(0.5791)\n",
      "Err Tr:  tensor([1.7309, 0.5647])\n",
      "Err Te:  tensor(1.9282) tensor(0.5749)\n",
      "Err Tr:  tensor([1.7016, 0.5619])\n",
      "Err Te:  tensor(1.8836) tensor(0.5919)\n",
      "Err Tr:  tensor([1.6597, 0.5570])\n",
      "Err Te:  tensor(1.5355) tensor(0.4942)\n",
      "Err Tr:  tensor([1.6273, 0.5550])\n",
      "Err Te:  tensor(1.5002) tensor(0.5607)\n",
      "Err Tr:  tensor([1.6202, 0.5526])\n",
      "Err Te:  tensor(1.5977) tensor(0.5741)\n",
      "Err Tr:  tensor([1.6029, 0.5494])\n",
      "Err Te:  tensor(1.8552) tensor(0.5265)\n",
      "Err Tr:  tensor([1.5853, 0.5473])\n",
      "Err Te:  tensor(1.6923) tensor(0.6167)\n",
      "Err Tr:  tensor([1.5802, 0.5455])\n",
      "Err Te:  tensor(1.5193) tensor(0.5695)\n",
      "Err Tr:  tensor([1.5662, 0.5426])\n",
      "Err Te:  tensor(1.2597) tensor(0.5548)\n",
      "Err Tr:  tensor([1.5573, 0.5411])\n",
      "Err Te:  tensor(1.4781) tensor(0.5653)\n",
      "Err Tr:  tensor([1.5436, 0.5388])\n",
      "Err Te:  tensor(1.7980) tensor(0.5455)\n",
      "Err Tr:  tensor([1.5270, 0.5357])\n",
      "Err Te:  tensor(1.6399) tensor(0.5821)\n",
      "Err Tr:  tensor([1.5125, 0.5354])\n",
      "Err Te:  tensor(1.6578) tensor(0.5577)\n",
      "Err Tr:  tensor([1.5068, 0.5312])\n",
      "Err Te:  tensor(1.3634) tensor(0.5567)\n",
      "Err Tr:  tensor([1.4926, 0.5272])\n",
      "Err Te:  tensor(1.5418) tensor(0.5308)\n",
      "Err Tr:  tensor([1.4865, 0.5242])\n",
      "Err Te:  tensor(1.4061) tensor(0.4858)\n",
      "Err Tr:  tensor([1.4734, 0.5203])\n",
      "Err Te:  tensor(1.4695) tensor(0.5363)\n",
      "Err Tr:  tensor([1.4551, 0.5136])\n",
      "Err Te:  tensor(1.9337) tensor(0.5448)\n",
      "Err Tr:  tensor([1.4452, 0.5081])\n",
      "Err Te:  tensor(1.3875) tensor(0.4576)\n",
      "Err Tr:  tensor([1.4352, 0.5013])\n",
      "Err Te:  tensor(1.2693) tensor(0.4486)\n",
      "Err Tr:  tensor([1.4158, 0.4929])\n",
      "Err Te:  tensor(1.5581) tensor(0.5463)\n",
      "Err Tr:  tensor([1.3951, 0.4846])\n",
      "Err Te:  tensor(1.5029) tensor(0.4452)\n",
      "Err Tr:  tensor([1.3798, 0.4757])\n",
      "Err Te:  tensor(1.4706) tensor(0.3920)\n",
      "Err Tr:  tensor([1.3616, 0.4680])\n",
      "Err Te:  tensor(1.6199) tensor(0.4564)\n",
      "Err Tr:  tensor([1.3455, 0.4595])\n",
      "Err Te:  tensor(1.3542) tensor(0.3901)\n",
      "Err Tr:  tensor([1.3276, 0.4516])\n",
      "Err Te:  tensor(1.4604) tensor(0.4455)\n",
      "Err Tr:  tensor([1.3091, 0.4437])\n",
      "Err Te:  tensor(1.3891) tensor(0.4014)\n",
      "Err Tr:  tensor([1.2933, 0.4365])\n",
      "Err Te:  tensor(1.4137) tensor(0.4478)\n",
      "Err Tr:  tensor([1.2745, 0.4294])\n",
      "Err Te:  tensor(1.3904) tensor(0.3861)\n",
      "Err Tr:  tensor([1.2570, 0.4228])\n",
      "Err Te:  tensor(0.9672) tensor(0.4196)\n",
      "Err Tr:  tensor([1.2397, 0.4161])\n",
      "Err Te:  tensor(1.1057) tensor(0.3750)\n",
      "Err Tr:  tensor([1.2232, 0.4097])\n",
      "Err Te:  tensor(1.2569) tensor(0.4111)\n",
      "Err Tr:  tensor([1.2082, 0.4037])\n",
      "Err Te:  tensor(1.5890) tensor(0.3931)\n",
      "Err Tr:  tensor([1.1916, 0.3982])\n",
      "Err Te:  tensor(1.6680) tensor(0.3973)\n",
      "Err Tr:  tensor([1.1767, 0.3934])\n",
      "Err Te:  tensor(1.4721) tensor(0.3927)\n",
      "Err Tr:  tensor([1.1630, 0.3888])\n",
      "Err Te:  tensor(1.7464) tensor(0.4031)\n",
      "Err Tr:  tensor([1.1479, 0.3843])\n",
      "Err Te:  tensor(1.4663) tensor(0.4969)\n",
      "Err Tr:  tensor([1.1332, 0.3803])\n",
      "Err Te:  tensor(1.6503) tensor(0.4063)\n",
      "Err Tr:  tensor([1.1201, 0.3764])\n",
      "Err Te:  tensor(1.0266) tensor(0.3776)\n",
      "Err Tr:  tensor([1.1050, 0.3725])\n",
      "Err Te:  tensor(1.3981) tensor(0.3630)\n",
      "Err Tr:  tensor([1.0911, 0.3692])\n",
      "Err Te:  tensor(1.1792) tensor(0.3287)\n",
      "Err Tr:  tensor([1.0778, 0.3664])\n",
      "Err Te:  tensor(1.8041) tensor(0.3926)\n",
      "Err Tr:  tensor([1.0647, 0.3634])\n",
      "Err Te:  tensor(1.5839) tensor(0.3750)\n",
      "Err Tr:  tensor([1.0521, 0.3608])\n",
      "Err Te:  tensor(1.4831) tensor(0.3889)\n",
      "Err Tr:  tensor([1.0398, 0.3581])\n",
      "Err Te:  tensor(1.3809) tensor(0.3234)\n",
      "Err Tr:  tensor([1.0289, 0.3555])\n",
      "Err Te:  tensor(2.1762) tensor(0.3819)\n",
      "Err Tr:  tensor([1.0173, 0.3528])\n",
      "Err Te:  tensor(1.2055) tensor(0.3396)\n",
      "Err Tr:  tensor([1.0061, 0.3502])\n",
      "Err Te:  tensor(1.3844) tensor(0.3660)\n",
      "Err Tr:  tensor([0.9954, 0.3476])\n",
      "Err Te:  tensor(1.1667) tensor(0.3443)\n",
      "Err Tr:  tensor([0.9851, 0.3451])\n",
      "Err Te:  tensor(1.1061) tensor(0.3993)\n",
      "Err Tr:  tensor([0.9757, 0.3426])\n",
      "Err Te:  tensor(1.3834) tensor(0.3750)\n",
      "Err Tr:  tensor([0.9666, 0.3404])\n",
      "Err Te:  tensor(0.8974) tensor(0.3341)\n",
      "Err Tr:  tensor([0.9573, 0.3382])\n",
      "Err Te:  tensor(1.2834) tensor(0.3706)\n",
      "Err Tr:  tensor([0.9488, 0.3362])\n",
      "Err Te:  tensor(1.1208) tensor(0.3526)\n",
      "Err Tr:  tensor([0.9401, 0.3342])\n",
      "Err Te:  tensor(1.6194) tensor(0.3566)\n"
     ]
    }
   ],
   "source": [
    "N_train=50000\n",
    "\n",
    "\n",
    "T_hor=50\n",
    "\n",
    "N_log=100\n",
    "N_checks=np.unique(np.int32(np.exp(np.linspace(0,np.log(N_train),N_log))))\n",
    "#N_checks=np.arange(0,101)*500\n",
    "N_check=N_checks.shape[0]\n",
    "\n",
    "ind_help=0\n",
    "\n",
    "LOAD=False\n",
    "SAVE=True\n",
    "PLOT=False\n",
    "\n",
    "\n",
    "if LOAD:\n",
    "\n",
    "    self_model=torch.load('Model_simple_after_corr_cutFalse_No_Bottle.pt')  \n",
    "    self_model.Override_Predictive(F_Ns, dt, lr=0.001)\n",
    "\n",
    "MSE_Train_pred=torch.zeros([2,N_train])\n",
    "\n",
    "MSE_Tr_pred=torch.zeros([2,N_check])\n",
    "T_hor_val=100\n",
    "MSE_Te_pred=torch.zeros([2,T_hor_val,N_check])\n",
    "\n",
    "t0s=torch.tensor(0.)\n",
    "ind_help=0\n",
    "\n",
    "for k in range(0,N_train):\n",
    "\n",
    "    X_b, Y_b, A_b, x0s, t0s=Data.Batch_ODE(batch_size, T_horizon=T_hor)\n",
    "        \n",
    "    err_original, err_latent, Z_recon, Y_recon, _, _=self_model.Predictive_forward(X_b,Y_b,A_b,t0s,TRAIN=True)\n",
    "\n",
    "    MSE_Train_pred[0,k]=err_latent.mean().detach()\n",
    "    MSE_Train_pred[1,k]=err_original.mean().detach()\n",
    "    \n",
    "    if k==N_checks[ind_help]:\n",
    "        \n",
    "        if k>0:\n",
    "            \n",
    "            mse_mean=torch.mean(MSE_Train_pred[:,k-N_checks[ind_help-1]:k],1)\n",
    "            MSE_Tr_pred[:,ind_help]=mse_mean\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            MSE_Tr_pred[:,ind_help]=MSE_Train_pred[:,k]\n",
    "            \n",
    "        \n",
    "        ## TESTING ##\n",
    "        #############\n",
    "\n",
    "        X_te, Y_te, A_te, x0s, t0s, lab_=Data.Evaluate_ODE(batch_size, T_horizon_val=T_hor_val)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            err_original, err_latent, Z_recon, Y_recon, Z_te, img_self=self_model.Predictive_forward(X_te,Y_te,A_te,t0s,TRAIN=False)\n",
    "\n",
    "        MSE_Te_pred[0,1:,ind_help]=err_latent.detach()\n",
    "        MSE_Te_pred[1,:,ind_help]=err_original.detach()\n",
    "        \n",
    "\n",
    "        print('Err Tr: ', MSE_Tr_pred[:,ind_help] )\n",
    "        print('Err Te: ', MSE_Te_pred[0,:,ind_help].mean(), MSE_Te_pred[1,:,ind_help].mean() ) \n",
    "        \n",
    "        ind_help=ind_help+1\n",
    "\n",
    "\n",
    "        if SAVE:\n",
    "\n",
    "            title_model='Model_simple_after_pred_cutFalse_Vision_only_0_Lpy.pt'\n",
    "            torch.save(self_model, title_model)\n",
    "\n",
    "            title_results='Results_simple_after_pred_cutFalse_Vision_only_0_Lpy'\n",
    "            np.savez(title_results, MSE_Train_pred=MSE_Train_pred, MSE_Tr_pred=MSE_Tr_pred, MSE_Te_pred=MSE_Te_pred, N_checks=N_checks)\n",
    "        \n",
    "        \n",
    "        if PLOT:\n",
    "\n",
    "            Z_te=Z_te.detach().to('cpu')\n",
    "            Z_recon=Z_recon.detach().to('cpu')\n",
    "    \n",
    "            Y_te=Y_te.detach().to('cpu')\n",
    "            Y_recon=Y_recon.detach().to('cpu')\n",
    "                \n",
    "            N_cases=3\n",
    "            fig, axs = plt.subplots(N_cases,2,figsize=(20,15))\n",
    "            \n",
    "            print('PLOTTING EXAMPLES OF MODEL PREDICTION VS DATA AT TRAINING ITERATION ', k)\n",
    "            \n",
    "            T_plot=200\n",
    "            for ind_ex in range(N_cases):\n",
    "    \n",
    "    \n",
    "                ind_ex_=np.random.randint(0,Z_te.size()[0])\n",
    "                axs[ind_ex,0].plot(Z_te[ind_ex_,0,0:T_plot].detach().to('cpu'),'o',color='red')\n",
    "                axs[ind_ex,0].plot(Z_recon[ind_ex_,0,0:T_plot].detach().to('cpu'),color='red', linewidth=2)\n",
    "                axs[ind_ex,0].plot(Z_te[ind_ex_,1,0:T_plot].detach().to('cpu'),'o',color='purple')\n",
    "                axs[ind_ex,0].plot(Z_recon[ind_ex_,1,0:T_plot].detach().to('cpu'),'--',color='purple', linewidth=2)\n",
    "                axs[ind_ex,0].plot(Z_te[ind_ex_,2,0:T_plot].detach().to('cpu'),'o',color='black')\n",
    "                axs[ind_ex,0].plot(Z_recon[ind_ex_,2,0:T_plot].detach().to('cpu'),'--',color='black', linewidth=2)\n",
    "    \n",
    "            \n",
    "                axs[ind_ex,1].plot(Y_te[ind_ex_,0,0:T_plot].detach().to('cpu'),'o',color='red')\n",
    "                axs[ind_ex,1].plot(Y_recon[ind_ex_,0,0:T_plot].detach().to('cpu'),color='red', linewidth=2)\n",
    "                axs[ind_ex,1].plot(Y_te[ind_ex_,1,0:T_plot].detach().to('cpu'),'o',color='purple')\n",
    "                axs[ind_ex,1].plot(Y_recon[ind_ex_,1,0:T_plot].detach().to('cpu'),'--',color='purple', linewidth=2)\n",
    "                axs[ind_ex,1].plot(Y_te[ind_ex_,2,0:T_plot].detach().to('cpu'),'o',color='black')\n",
    "                axs[ind_ex,1].plot(Y_recon[ind_ex_,2,0:T_plot].detach().to('cpu'),'--',color='black', linewidth=2)\n",
    "    \n",
    "    \n",
    "    \n",
    "                axs[ind_ex,0].set_xlabel('Time (a.u.)', fontsize=20)\n",
    "                axs[ind_ex,0].set_ylabel('Values', fontsize=20)\n",
    "    \n",
    "                axs[ind_ex,0].spines['right'].set_visible(False)\n",
    "                axs[ind_ex,0].spines['top'].set_visible(False)\n",
    "    \n",
    "                axs[ind_ex,1].set_xlabel('Time (a.u.)', fontsize=20)\n",
    "                axs[ind_ex,1].set_ylabel('Values', fontsize=20)\n",
    "    \n",
    "                axs[ind_ex,1].spines['right'].set_visible(False)\n",
    "                axs[ind_ex,1].spines['top'].set_visible(False)\n",
    "    \n",
    "    \n",
    "            plt.show()\n",
    "\n",
    "            fig, axs = plt.subplots(1,img_self.size()[1],figsize=(20,15))\n",
    "\n",
    "            for n in range(img_self.size()[1]):\n",
    "\n",
    "                axs[n].imshow(img_self[0,n,...].permute(1,2,0).detach().to('cpu'))\n",
    "\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcda496-a002-4281-af61-36fd2f1d0094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
